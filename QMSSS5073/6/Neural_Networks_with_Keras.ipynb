{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qecTR8_jAH9Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.25.11) or chardet (2.0.3)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# Install tensorflow and keras libraries first.  Code in command prompt:\n",
    "##     conda install -c conda-forge tensorflow, keras\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# The core data structure of Keras is a model, a way to organize layers.\n",
    "\n",
    "model = Sequential() # Define the architecture of you model using Sequential.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZJO44sCCAH9f",
    "outputId": "4c029771-74a2-48fb-e0ff-f03c92e23c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                25120     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,275\n",
      "Trainable params: 26,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build layers with Dense, followed by Activation()...\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "# two hidden layers with 32 nodes\n",
    "# Activation is set to relu\n",
    "# one output layer with 10 categories.  \n",
    "# softmax function used to calculate 0 to 1 probabilities for each of 10 categories\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(32),\n",
    "    Activation('relu'),\n",
    "    Dense(3),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYWdU1yOAH9i",
    "outputId": "645e84ca-3a6f-432c-9ac0-1022de383254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 32)                25120     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,562\n",
      "Trainable params: 27,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model with three hidden layers\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(32),\n",
    "    Activation('relu'),\n",
    "    Dense(32),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBixh7ZeAH9k",
    "outputId": "4f7164bd-8664-4b8f-be90-aab723230f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,465\n",
      "Trainable params: 54,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Or build a model in steps using .add():\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential() \n",
    "model.add(Dense(units=64, activation='relu', input_dim=784))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXucdUgJAH9n"
   },
   "outputs": [],
   "source": [
    "# Once your model looks good, configure its learning process with .compile():\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_S2EiUcAAH9p"
   },
   "source": [
    "**loss can be set to:**\n",
    "    - 'categorical_crossentropy' for multiple categories\n",
    "    - 'binary_crossentropy' for binary categories\n",
    "    - 'mse' for regression, which calculates the mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YYoImfwAH9p"
   },
   "source": [
    "**optimizer can be set to 'sgd' for stochastic gradient descent or a variety of other techniques.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSGiGFwfAH9q"
   },
   "source": [
    "## Training a keras model\n",
    "\n",
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the  fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4zJrGrjAH9q",
    "outputId": "bb510745-9f86-4827-f11e-bd29ea86a494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 9ms/step - loss: 0.7243 - accuracy: 0.4975 - val_loss: 0.7155 - val_accuracy: 0.5100\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7065 - accuracy: 0.4925 - val_loss: 0.7137 - val_accuracy: 0.5200\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.4825 - val_loss: 0.7163 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.5025 - val_loss: 0.7153 - val_accuracy: 0.5050\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7013 - accuracy: 0.4900 - val_loss: 0.7131 - val_accuracy: 0.5150\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.5088 - val_loss: 0.7158 - val_accuracy: 0.4900\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.5013 - val_loss: 0.7149 - val_accuracy: 0.4900\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.5013 - val_loss: 0.7153 - val_accuracy: 0.4900\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.5050 - val_loss: 0.7123 - val_accuracy: 0.5100\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.5088 - val_loss: 0.7128 - val_accuracy: 0.5050\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.7142 - val_accuracy: 0.4850\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5312 - val_loss: 0.7118 - val_accuracy: 0.4950\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5150 - val_loss: 0.7147 - val_accuracy: 0.4800\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5088 - val_loss: 0.7172 - val_accuracy: 0.4650\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.5387 - val_loss: 0.7135 - val_accuracy: 0.4750\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5350 - val_loss: 0.7137 - val_accuracy: 0.4800\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5475 - val_loss: 0.7129 - val_accuracy: 0.4900\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5400 - val_loss: 0.7138 - val_accuracy: 0.4700\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5475 - val_loss: 0.7134 - val_accuracy: 0.4750\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5487 - val_loss: 0.7124 - val_accuracy: 0.4800\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5537 - val_loss: 0.7147 - val_accuracy: 0.4650\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.5450 - val_loss: 0.7138 - val_accuracy: 0.4600\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5412 - val_loss: 0.7161 - val_accuracy: 0.4750\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5612 - val_loss: 0.7124 - val_accuracy: 0.4700\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.5450 - val_loss: 0.7144 - val_accuracy: 0.4600\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.5600 - val_loss: 0.7123 - val_accuracy: 0.4650\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.5475 - val_loss: 0.7136 - val_accuracy: 0.4600\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5500 - val_loss: 0.7147 - val_accuracy: 0.4700\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.5625 - val_loss: 0.7148 - val_accuracy: 0.4700\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.5500 - val_loss: 0.7186 - val_accuracy: 0.4800\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.5537 - val_loss: 0.7153 - val_accuracy: 0.4700\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5650 - val_loss: 0.7138 - val_accuracy: 0.4700\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.5688 - val_loss: 0.7146 - val_accuracy: 0.4700\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5675 - val_loss: 0.7137 - val_accuracy: 0.4650\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.5688 - val_loss: 0.7153 - val_accuracy: 0.4800\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.5713 - val_loss: 0.7170 - val_accuracy: 0.4850\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.5763 - val_loss: 0.7145 - val_accuracy: 0.4750\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.5738 - val_loss: 0.7158 - val_accuracy: 0.4850\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.5850 - val_loss: 0.7128 - val_accuracy: 0.4500\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5850 - val_loss: 0.7136 - val_accuracy: 0.4550\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.5850 - val_loss: 0.7156 - val_accuracy: 0.4800\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.5850 - val_loss: 0.7148 - val_accuracy: 0.4700\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.5938 - val_loss: 0.7138 - val_accuracy: 0.4500\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.5938 - val_loss: 0.7149 - val_accuracy: 0.4700\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.5913 - val_loss: 0.7158 - val_accuracy: 0.4850\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.5962 - val_loss: 0.7130 - val_accuracy: 0.4700\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.5950 - val_loss: 0.7170 - val_accuracy: 0.4700\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.5938 - val_loss: 0.7144 - val_accuracy: 0.4550\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.5863 - val_loss: 0.7152 - val_accuracy: 0.4650\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.6012 - val_loss: 0.7164 - val_accuracy: 0.4750\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.5925 - val_loss: 0.7152 - val_accuracy: 0.4650\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.5987 - val_loss: 0.7152 - val_accuracy: 0.4650\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.6000 - val_loss: 0.7159 - val_accuracy: 0.4650\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.6037 - val_loss: 0.7199 - val_accuracy: 0.4650\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6162 - val_loss: 0.7156 - val_accuracy: 0.4650\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6012 - val_loss: 0.7174 - val_accuracy: 0.4650\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6012 - val_loss: 0.7167 - val_accuracy: 0.4600\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.6000 - val_loss: 0.7171 - val_accuracy: 0.4650\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6050 - val_loss: 0.7153 - val_accuracy: 0.4550\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6125 - val_loss: 0.7167 - val_accuracy: 0.4650\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6087 - val_loss: 0.7189 - val_accuracy: 0.4600\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.5962 - val_loss: 0.7178 - val_accuracy: 0.4600\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6112 - val_loss: 0.7156 - val_accuracy: 0.4550\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6087 - val_loss: 0.7153 - val_accuracy: 0.4550\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.6212 - val_loss: 0.7170 - val_accuracy: 0.4650\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6137 - val_loss: 0.7173 - val_accuracy: 0.4700\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6125 - val_loss: 0.7180 - val_accuracy: 0.4700\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6200 - val_loss: 0.7187 - val_accuracy: 0.4650\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.6250 - val_loss: 0.7176 - val_accuracy: 0.4650\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.6162 - val_loss: 0.7170 - val_accuracy: 0.4650\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.6175 - val_loss: 0.7152 - val_accuracy: 0.4600\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6175 - val_loss: 0.7162 - val_accuracy: 0.4650\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6237 - val_loss: 0.7167 - val_accuracy: 0.4600\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6275 - val_loss: 0.7201 - val_accuracy: 0.4650\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.6263 - val_loss: 0.7216 - val_accuracy: 0.4600\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6300 - val_loss: 0.7199 - val_accuracy: 0.4600\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.6300 - val_loss: 0.7172 - val_accuracy: 0.4650\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.6250 - val_loss: 0.7190 - val_accuracy: 0.4600\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.6275 - val_loss: 0.7204 - val_accuracy: 0.4600\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.6263 - val_loss: 0.7197 - val_accuracy: 0.4600\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.6263 - val_loss: 0.7180 - val_accuracy: 0.4600\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.6325 - val_loss: 0.7188 - val_accuracy: 0.4550\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6504 - accuracy: 0.6288 - val_loss: 0.7199 - val_accuracy: 0.4550\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.6325 - val_loss: 0.7199 - val_accuracy: 0.4550\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.6400 - val_loss: 0.7184 - val_accuracy: 0.4500\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.6438 - val_loss: 0.7191 - val_accuracy: 0.4500\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6474 - accuracy: 0.6400 - val_loss: 0.7225 - val_accuracy: 0.4600\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.6325 - val_loss: 0.7213 - val_accuracy: 0.4650\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.6350 - val_loss: 0.7204 - val_accuracy: 0.4550\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6338 - val_loss: 0.7202 - val_accuracy: 0.4500\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.6338 - val_loss: 0.7195 - val_accuracy: 0.4600\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6413 - val_loss: 0.7214 - val_accuracy: 0.4550\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.6275 - val_loss: 0.7208 - val_accuracy: 0.4450\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.6400 - val_loss: 0.7201 - val_accuracy: 0.4550\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.6363 - val_loss: 0.7212 - val_accuracy: 0.4450\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.6350 - val_loss: 0.7209 - val_accuracy: 0.4500\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.6363 - val_loss: 0.7217 - val_accuracy: 0.4550\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6450 - val_loss: 0.7237 - val_accuracy: 0.4450\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.6375 - val_loss: 0.7205 - val_accuracy: 0.4650\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6425 - val_loss: 0.7234 - val_accuracy: 0.4400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50c3cc6550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']) # Change to 'AUC' for ROC area under the curve\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100)) # X data\n",
    "labels = np.random.randint(2, size=(1000, 1)) # y data\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, labels, validation_split=0.20, epochs=100, batch_size=32)\n",
    "\n",
    "#Note that you can also use train_test_split() with , validation_data=(X_test,y_test) argument from Keras in same manner.\n",
    "##Split data first and then simply train on training data and add test data to this argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9rrVgbrAH9t",
    "outputId": "c950d519-5903-4fee-851c-7b9347ca487d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3652 - accuracy: 0.0960\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3652 - accuracy: 0.0970\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3651 - accuracy: 0.0970\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3650 - accuracy: 0.0970\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3650 - accuracy: 0.0970\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3649 - accuracy: 0.0970\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3648 - accuracy: 0.0970\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3648 - accuracy: 0.0970\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3647 - accuracy: 0.0970\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3646 - accuracy: 0.0970\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3646 - accuracy: 0.0970\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3645 - accuracy: 0.0970\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3644 - accuracy: 0.0970\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3644 - accuracy: 0.0970\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3643 - accuracy: 0.0970\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3642 - accuracy: 0.0970\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3642 - accuracy: 0.0970\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3641 - accuracy: 0.0970\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3640 - accuracy: 0.0960\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3640 - accuracy: 0.0950\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.3461 - accuracy: 0.0800\n",
      "[2.346099376678467, 0.07999999821186066]\n"
     ]
    }
   ],
   "source": [
    "# for multiple categories you  need to one hot encode y using to_categorical()\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(32, activation='relu', input_dim=20))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.0001)  # define a learning rate for optimization\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128) # extract loss and accuracy from test data evaluation\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxEI52VDAH9w",
    "outputId": "3146197a-945d-4c30-d468-9c08e8270435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20)\n",
      "[[0.11060342 0.0602899  0.08755879 0.1260634  0.10158405 0.09519875\n",
      "  0.18700692 0.13430193 0.04593942 0.05145344]\n",
      " [0.09921195 0.0960526  0.1118855  0.11626416 0.10949366 0.07774754\n",
      "  0.12657063 0.11333689 0.06405037 0.08538666]\n",
      " [0.11792949 0.06417657 0.08813304 0.11985773 0.11452303 0.10474874\n",
      "  0.15062857 0.10512523 0.07712695 0.05775067]\n",
      " [0.11241822 0.07289915 0.09647147 0.09193511 0.09141736 0.06876262\n",
      "  0.17307672 0.16160233 0.07954331 0.0518738 ]\n",
      " [0.09097541 0.05326476 0.07314683 0.14915232 0.08540157 0.09484611\n",
      "  0.21941434 0.13094403 0.06106304 0.04179153]\n",
      " [0.11678486 0.04377655 0.06806418 0.1343183  0.10215937 0.14528261\n",
      "  0.18438137 0.09315809 0.05254824 0.05952638]\n",
      " [0.10972705 0.07544528 0.08834139 0.11817972 0.11598153 0.11722534\n",
      "  0.11893305 0.10424281 0.06779786 0.08412599]\n",
      " [0.11116984 0.03501162 0.07656498 0.12849803 0.12324934 0.13015528\n",
      "  0.17471662 0.09989025 0.06329314 0.05745092]\n",
      " [0.13210721 0.0660553  0.0801582  0.10919275 0.09212031 0.10872161\n",
      "  0.17172655 0.12481672 0.05583834 0.05926292]\n",
      " [0.10060935 0.13589312 0.12252491 0.09557467 0.10752194 0.07092071\n",
      "  0.11148043 0.12448671 0.0610536  0.06993458]\n",
      " [0.13050684 0.06172162 0.07682196 0.11811411 0.11603038 0.11917879\n",
      "  0.1400262  0.11280616 0.05578339 0.06901047]\n",
      " [0.10422862 0.06413106 0.07700835 0.13201499 0.11157157 0.14944954\n",
      "  0.11664298 0.10029849 0.06260454 0.0820499 ]\n",
      " [0.13096471 0.07648911 0.08790318 0.11468384 0.10488915 0.08922391\n",
      "  0.12789048 0.12641011 0.0721286  0.06941691]\n",
      " [0.13557328 0.09355326 0.11673595 0.08251636 0.12057646 0.08391821\n",
      "  0.11005655 0.12751688 0.07667034 0.05288267]\n",
      " [0.11395757 0.07160071 0.09507925 0.11861519 0.1111327  0.10709135\n",
      "  0.14471073 0.10095013 0.06404795 0.07281446]\n",
      " [0.13340707 0.06722974 0.09165286 0.1093994  0.10789868 0.08446141\n",
      "  0.14842306 0.14282884 0.06111242 0.05358654]\n",
      " [0.1169377  0.066941   0.0914959  0.09096072 0.10181881 0.08197043\n",
      "  0.16743627 0.14118557 0.09111259 0.05014103]\n",
      " [0.11272279 0.04799356 0.08172294 0.12664162 0.11857644 0.11877412\n",
      "  0.14604913 0.11710017 0.06413918 0.06628006]\n",
      " [0.13687916 0.06153454 0.07221095 0.14211568 0.10431026 0.11569091\n",
      "  0.15021771 0.09995956 0.05353424 0.06354697]\n",
      " [0.14205149 0.06551346 0.07219461 0.10101111 0.10913109 0.12863219\n",
      "  0.14515474 0.09913921 0.06465452 0.07251748]\n",
      " [0.10663048 0.06151026 0.09322437 0.12269666 0.11290376 0.09808414\n",
      "  0.1470713  0.11601701 0.07747079 0.06439119]\n",
      " [0.11044744 0.07758161 0.09199298 0.12059533 0.1030582  0.10374667\n",
      "  0.14395241 0.0996045  0.07308229 0.07593852]\n",
      " [0.0885812  0.03738944 0.07449913 0.10353068 0.07896931 0.08514344\n",
      "  0.27561757 0.1513833  0.07080118 0.03408469]\n",
      " [0.11644244 0.06690383 0.09217881 0.11374618 0.0960194  0.09453261\n",
      "  0.15976463 0.11452779 0.07087112 0.07501323]\n",
      " [0.13608202 0.05201333 0.07023683 0.1318328  0.09152048 0.12414147\n",
      "  0.14834508 0.13032678 0.04916707 0.06633418]\n",
      " [0.10612529 0.07359412 0.10284927 0.12017118 0.12263587 0.0813254\n",
      "  0.14824015 0.10936101 0.07886989 0.05682785]\n",
      " [0.13969418 0.06696964 0.08485286 0.12188989 0.09861216 0.10727788\n",
      "  0.14918458 0.10872252 0.05787203 0.06492432]\n",
      " [0.11845109 0.06492449 0.07978056 0.13117813 0.10751572 0.11700389\n",
      "  0.13065742 0.11565025 0.06023817 0.07460028]\n",
      " [0.10818341 0.04064419 0.06823361 0.15082882 0.10458399 0.16130632\n",
      "  0.17480412 0.09294969 0.04269096 0.05577489]\n",
      " [0.12100229 0.08138639 0.08482482 0.11989098 0.10046876 0.10230331\n",
      "  0.13089596 0.11365519 0.06690451 0.0786678 ]\n",
      " [0.13984531 0.059951   0.07110841 0.11602189 0.09866372 0.10582983\n",
      "  0.17847635 0.14043424 0.04243293 0.04723634]\n",
      " [0.11602758 0.0559011  0.08119126 0.12359691 0.11697344 0.12315576\n",
      "  0.15437828 0.11448976 0.05154998 0.06273588]\n",
      " [0.12984632 0.08282419 0.0884965  0.10694491 0.11126781 0.10548604\n",
      "  0.11627062 0.12041693 0.06682011 0.07162663]\n",
      " [0.11995655 0.08099877 0.11245899 0.10636932 0.11505703 0.08962725\n",
      "  0.13320139 0.11091092 0.05977485 0.07164489]\n",
      " [0.12904705 0.05170319 0.08323088 0.10877741 0.12274932 0.10241915\n",
      "  0.15627402 0.1293014  0.06627842 0.05021916]\n",
      " [0.11245853 0.04690593 0.07834883 0.14212438 0.08878426 0.08665184\n",
      "  0.23793161 0.0950677  0.05188937 0.0598376 ]\n",
      " [0.11451273 0.06249293 0.07904313 0.13561192 0.09387464 0.1034959\n",
      "  0.17731327 0.11924166 0.06426717 0.05014657]\n",
      " [0.11519066 0.05674609 0.07043044 0.14521806 0.10235889 0.11988746\n",
      "  0.15661746 0.09688567 0.06252436 0.07414087]\n",
      " [0.13486831 0.05924854 0.08732472 0.11109853 0.11380081 0.09934638\n",
      "  0.14576231 0.12941171 0.05842908 0.06070969]\n",
      " [0.10752685 0.05120745 0.07282541 0.13260731 0.10552553 0.11942643\n",
      "  0.16462986 0.10140535 0.06424318 0.08060253]\n",
      " [0.11860064 0.07133351 0.0971071  0.11149234 0.11216278 0.08240768\n",
      "  0.14478771 0.1398555  0.06066782 0.06158498]\n",
      " [0.10753319 0.05309782 0.08361172 0.13830134 0.12020347 0.11000882\n",
      "  0.1500205  0.10493449 0.07274257 0.05954618]\n",
      " [0.10168227 0.05050426 0.08287013 0.12248304 0.12360628 0.1312941\n",
      "  0.16735715 0.0895768  0.06522098 0.06540504]\n",
      " [0.13468492 0.07071199 0.087989   0.11745966 0.1242435  0.1302665\n",
      "  0.11500905 0.09382255 0.05343385 0.07237904]\n",
      " [0.12044989 0.08829583 0.09846919 0.10724569 0.11683343 0.1046309\n",
      "  0.11439245 0.11965903 0.05593106 0.07409252]\n",
      " [0.12309797 0.05711144 0.09280641 0.11696015 0.09323879 0.07530142\n",
      "  0.17541058 0.14850776 0.06960491 0.0479606 ]\n",
      " [0.11999606 0.07076321 0.10349673 0.09949335 0.11170262 0.09265098\n",
      "  0.15050642 0.11501126 0.07191011 0.06446923]\n",
      " [0.10293149 0.06593388 0.08125824 0.10181379 0.11638094 0.11448655\n",
      "  0.16816434 0.12256403 0.05431595 0.07215075]\n",
      " [0.12683901 0.06316368 0.09249688 0.09319134 0.11526379 0.08848946\n",
      "  0.15573877 0.15250397 0.05978067 0.05253243]\n",
      " [0.11851852 0.05847939 0.08963176 0.123405   0.09955997 0.10368175\n",
      "  0.15936927 0.10121904 0.07165284 0.0744824 ]\n",
      " [0.13265018 0.06729142 0.09383272 0.10842507 0.11018462 0.08885952\n",
      "  0.16386327 0.11568829 0.0651922  0.05401273]\n",
      " [0.10752618 0.06511944 0.09058256 0.11774036 0.09967328 0.10316221\n",
      "  0.17576851 0.10787773 0.07264302 0.05990666]\n",
      " [0.12418391 0.06609046 0.09360234 0.12187069 0.10129754 0.07724269\n",
      "  0.1708949  0.12582836 0.06345382 0.05553525]\n",
      " [0.12361574 0.05518028 0.07587218 0.12593012 0.11573236 0.13112722\n",
      "  0.1487336  0.10683366 0.05851019 0.0584646 ]\n",
      " [0.13965248 0.06992098 0.08101557 0.11798363 0.11914191 0.11023605\n",
      "  0.12432248 0.11570178 0.05772323 0.06430189]\n",
      " [0.11861144 0.04332756 0.07516966 0.09069626 0.08077    0.08002137\n",
      "  0.23321016 0.1553428  0.07018496 0.05266573]\n",
      " [0.11737137 0.04746383 0.07958002 0.13735877 0.10306843 0.10735501\n",
      "  0.18490334 0.09825205 0.06823968 0.05640744]\n",
      " [0.10454045 0.06092908 0.08408126 0.13075867 0.10099501 0.10407452\n",
      "  0.15064712 0.1175257  0.07322922 0.07321899]\n",
      " [0.11845713 0.06627534 0.09745546 0.11235033 0.11348227 0.08457104\n",
      "  0.14709985 0.12838271 0.08266383 0.04926204]\n",
      " [0.10214762 0.07017107 0.08684126 0.09580375 0.10314872 0.09785045\n",
      "  0.18273145 0.1246469  0.05855518 0.07810368]\n",
      " [0.11052962 0.05560465 0.08427218 0.12110892 0.10848736 0.12448418\n",
      "  0.15727632 0.11233185 0.06344654 0.06245835]\n",
      " [0.11366324 0.0573947  0.08197907 0.11683241 0.105769   0.1002804\n",
      "  0.19064756 0.10584467 0.0716139  0.05597495]\n",
      " [0.10414703 0.07623057 0.08127396 0.11413483 0.09467288 0.10158958\n",
      "  0.16970147 0.1217602  0.05509926 0.08139025]\n",
      " [0.1050455  0.04718032 0.07482746 0.13417447 0.116256   0.14163959\n",
      "  0.16889341 0.09017789 0.05996346 0.06184189]\n",
      " [0.11183299 0.04314003 0.06466039 0.14996217 0.10550558 0.1119355\n",
      "  0.1984314  0.0899201  0.0634729  0.06113896]\n",
      " [0.1058368  0.06993817 0.0744658  0.13488008 0.09431542 0.12805489\n",
      "  0.17661904 0.10961004 0.04761406 0.05866573]\n",
      " [0.13358118 0.06350528 0.07475433 0.12670574 0.08707108 0.09460418\n",
      "  0.18755798 0.1400161  0.0562316  0.0359725 ]\n",
      " [0.11896494 0.07850067 0.09960222 0.10705959 0.11257964 0.09142647\n",
      "  0.12790854 0.12195329 0.07701174 0.06499284]\n",
      " [0.10492981 0.05677374 0.07424465 0.14958009 0.10726511 0.1389273\n",
      "  0.12835696 0.08979193 0.07539534 0.07473501]\n",
      " [0.11673986 0.06341612 0.0796745  0.14538561 0.11267439 0.10773262\n",
      "  0.14025079 0.09724158 0.06994003 0.06694453]\n",
      " [0.12497637 0.0892852  0.09283516 0.10313395 0.09661844 0.08750991\n",
      "  0.11697322 0.12763754 0.08363966 0.07739057]\n",
      " [0.10961776 0.06883863 0.09488124 0.14208378 0.10020804 0.0745614\n",
      "  0.18122658 0.11335828 0.0660813  0.04914305]\n",
      " [0.11260589 0.06570572 0.07414715 0.14121373 0.09805988 0.13471895\n",
      "  0.14982891 0.10313906 0.05805005 0.06253066]\n",
      " [0.10266188 0.07533047 0.11083607 0.09549817 0.11149853 0.0702269\n",
      "  0.16715007 0.15236229 0.06596984 0.04846581]\n",
      " [0.11408507 0.04615945 0.07197735 0.14635548 0.09201737 0.08947162\n",
      "  0.20114405 0.11923178 0.06694534 0.05261262]\n",
      " [0.11930662 0.05553821 0.07783788 0.1069927  0.0967222  0.11527576\n",
      "  0.18226859 0.13376266 0.04610256 0.06619284]\n",
      " [0.15067564 0.08559475 0.09742572 0.09556959 0.11247654 0.07057595\n",
      "  0.12285929 0.14453676 0.06712484 0.05316091]\n",
      " [0.11973267 0.08238048 0.09527814 0.10882156 0.10814023 0.08347795\n",
      "  0.13119398 0.11781964 0.07896443 0.07419091]\n",
      " [0.09186164 0.05420436 0.08777668 0.13377552 0.11120355 0.12880163\n",
      "  0.17738795 0.10309987 0.05981764 0.05207118]\n",
      " [0.12917402 0.05330176 0.07531541 0.11160416 0.10843797 0.10564496\n",
      "  0.18167111 0.12034888 0.05853309 0.05596855]\n",
      " [0.08941843 0.07141044 0.09745797 0.11828922 0.09803198 0.10488888\n",
      "  0.19069432 0.11930723 0.05489069 0.05561088]\n",
      " [0.14064433 0.05063798 0.05935565 0.15450102 0.09858071 0.13239352\n",
      "  0.17853308 0.08657282 0.04560048 0.05318043]\n",
      " [0.11642496 0.07430467 0.09945277 0.07583962 0.1086519  0.10366401\n",
      "  0.14542389 0.14341597 0.07003904 0.06278312]\n",
      " [0.11746714 0.05177427 0.07007258 0.14785703 0.10307296 0.12612791\n",
      "  0.16763173 0.09605725 0.05534422 0.06459494]\n",
      " [0.12414917 0.08238745 0.08252183 0.13064133 0.10253213 0.1023838\n",
      "  0.12852381 0.10055532 0.07015073 0.07615439]\n",
      " [0.11142394 0.07093598 0.08327606 0.1060117  0.10872392 0.12449358\n",
      "  0.1211163  0.10660105 0.07787132 0.08954613]\n",
      " [0.12249126 0.08970537 0.10607382 0.10018214 0.09718679 0.08862524\n",
      "  0.14984335 0.10540102 0.0651075  0.07538349]\n",
      " [0.09975815 0.06171726 0.07786042 0.10370933 0.08070622 0.09788508\n",
      "  0.21816471 0.12651882 0.07838371 0.05529622]\n",
      " [0.13604076 0.07127795 0.08862542 0.08809496 0.13681138 0.09159411\n",
      "  0.12954767 0.13683805 0.06766351 0.05350618]\n",
      " [0.11611114 0.09984225 0.11501818 0.08845198 0.11864335 0.06785347\n",
      "  0.10555222 0.13107485 0.09825157 0.05920094]\n",
      " [0.13428697 0.07309457 0.0774338  0.09627376 0.10649273 0.11806621\n",
      "  0.1460757  0.11806396 0.06087724 0.06933504]\n",
      " [0.10416491 0.06830151 0.08243681 0.12583724 0.09222255 0.12609042\n",
      "  0.17574397 0.10635879 0.04855689 0.07028695]\n",
      " [0.13447921 0.06616873 0.07074587 0.11228125 0.08084717 0.12255162\n",
      "  0.1573461  0.12441154 0.05090495 0.08026366]\n",
      " [0.10496529 0.05451239 0.07942573 0.13919272 0.10376    0.12040634\n",
      "  0.14002398 0.11153148 0.06579791 0.08038411]\n",
      " [0.1293372  0.08151668 0.09204119 0.11283333 0.08471285 0.08067653\n",
      "  0.1679363  0.12642945 0.0596696  0.06484688]\n",
      " [0.09272359 0.05649657 0.07560474 0.13473542 0.1106471  0.14010581\n",
      "  0.129309   0.10937306 0.06636547 0.08463924]\n",
      " [0.11207601 0.07975012 0.07994992 0.1095527  0.1028147  0.09982074\n",
      "  0.15784107 0.1389689  0.05288155 0.06634423]\n",
      " [0.11402187 0.0679848  0.10483641 0.10712863 0.11960689 0.08697084\n",
      "  0.15326743 0.10782485 0.07452451 0.0638338 ]\n",
      " [0.12188517 0.07094466 0.0846936  0.10867596 0.11016318 0.11633812\n",
      "  0.15283602 0.11071355 0.05738069 0.06636906]\n",
      " [0.10871361 0.06024912 0.10069897 0.1183544  0.09271093 0.06406137\n",
      "  0.18477932 0.15996793 0.0576654  0.05279896]]\n",
      "[6 6 6 6 6 6 6 6 6 1 6 5 0 0 6 6 6 6 6 6 6 6 6 6 6 6 6 3 6 6 6 6 0 6 6 6 6\n",
      " 6 6 6 6 6 6 0 0 6 6 6 6 6 6 6 6 6 0 6 6 6 6 6 6 6 6 6 6 6 6 6 3 3 7 6 6 6\n",
      " 6 6 0 6 6 6 6 6 6 6 3 5 6 6 7 7 6 6 6 6 6 5 6 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prediction from keras classification model\n",
    "print(x_test.shape)\n",
    "\n",
    "\n",
    "# for predicted probabilities\n",
    "ypreds = model.predict(x_test)\n",
    "print(ypreds) #gives prediction of each category, largest is selected for predict_classes()\n",
    "\n",
    "\n",
    "# for predicted label index of one hot encoded y data columns\n",
    "# Can use this to return correct label from well ordered list of labels\n",
    "ypreds_classindex = np.argmax(model.predict(x_test), axis=-1)\n",
    "print(ypreds_classindex) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "HH52oduKBPqJ",
    "outputId": "3e774d82-2829-49b7-82f9-4d18cc38f84b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'label2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=[\"label1\",\"label2\"]\n",
    "\n",
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrHFjTzAAH9z",
    "outputId": "062eaffa-880e-4876-ae64-2c4b2f673215"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction from keras regression model\n",
    "\n",
    "# for predicted probabilities and labels\n",
    "ypreds = model.predict(x_test)\n",
    "\n",
    "# What is the index location of the column with the largest probability?\n",
    "ypreds[0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSq8BmngAH-C"
   },
   "source": [
    "## Now you try.  Can you fit a neural network model to the Iris dataset?  Run models that change the structure of the network (i.e.-hidden layers and activations).  Try to improve your validation accuracy as much as possible.\n",
    "\n",
    "Data can be imported via the following link:\n",
    "\n",
    "http://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tPGjX9vcAH-D",
    "outputId": "93499813-5f9d-42c3-e152-c0793da6813c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-18a41798-a7cc-4041-b137-699a9355cb60\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18a41798-a7cc-4041-b137-699a9355cb60')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-18a41798-a7cc-4041-b137-699a9355cb60 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-18a41798-a7cc-4041-b137-699a9355cb60');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     setosa  versicolor  virginica\n",
       "0         1           0          0\n",
       "1         1           0          0\n",
       "2         1           0          0\n",
       "3         1           0          0\n",
       "4         1           0          0\n",
       "..      ...         ...        ...\n",
       "145       0           0          1\n",
       "146       0           0          1\n",
       "147       0           0          1\n",
       "148       0           0          1\n",
       "149       0           0          1\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1925ef5a-93e5-4fda-97dc-3166d78826db\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1925ef5a-93e5-4fda-97dc-3166d78826db')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1925ef5a-93e5-4fda-97dc-3166d78826db button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1925ef5a-93e5-4fda-97dc-3166d78826db');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bb8f35b7-1d04-4130-81cf-44fb66da1938\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb8f35b7-1d04-4130-81cf-44fb66da1938')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bb8f35b7-1d04-4130-81cf-44fb66da1938 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bb8f35b7-1d04-4130-81cf-44fb66da1938');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0          setosa\n",
       "10         setosa\n",
       "20         setosa\n",
       "30         setosa\n",
       "40         setosa\n",
       "50     versicolor\n",
       "60     versicolor\n",
       "70     versicolor\n",
       "80     versicolor\n",
       "90     versicolor\n",
       "100     virginica\n",
       "110     virginica\n",
       "120     virginica\n",
       "130     virginica\n",
       "140     virginica\n",
       "Name: Species, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"http://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv\")\n",
    "\n",
    "\n",
    "#update data to set up for train test split\n",
    "data = data.iloc[:,1:]\n",
    "y = data['Species']\n",
    "X = data.loc[:, data.columns != 'Species']\n",
    "\n",
    "display(pd.get_dummies(y))\n",
    "display(data.head())\n",
    "display(X.head())\n",
    "display(y[0::10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak12E635AH-I"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Networks with Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
