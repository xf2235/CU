{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Outlier Detection (PyOD) Autoencoder\n",
    "\n",
    "- Environment: Python 3.6\n",
    "- Installation: [PyOD](https://github.com/yzhao062/pyod)\n",
    "- pip install combo\n",
    "- You can find all the algorithms of PyOD [here](https://pyod.readthedocs.io/en/latest/) and [here](https://pyod.readthedocs.io/en/latest/pyod.html).\n",
    "**Learning Objectives:**\n",
    "- Understand PyOD\n",
    "- Use autoencoder to build three models: clf1, clf2, clf3\n",
    "- Combination Methods\n",
    "**Assignment:**\n",
    "- Please select two algorithms to apply to your dataset.\n",
    "- Your analysis should provide a clear description for each of the algorithm and the results.\n",
    "- Your work should perform the combination methods.\n",
    "- Justify your identification for the anomalies with the data attributes.\n",
    "**First, we generate a dataframe with outliers**\n",
    "- There are total 500 obsservations including 10%, or 50, outliers\n",
    "- In your assignment, split your dataset to be X_train and X_test. Then you can follow accordingly.\n",
    "- We do not use the iris dataset because it only has 4 variables. We build a large dataset with 25 variables in order to show the power of neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyod            # normal install\n",
    "#!pip install --upgrade pyod  # or update if needed\n",
    "#!pip install combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.utils.data import generate_data\n",
    "#from pyod.utils.data import evaluate_print\n",
    "#from pyod.utils.example import visualize\n",
    "\n",
    "contamination = 0.1  # percentage of outliers\n",
    "n_train = 500  # number of training points\n",
    "n_test = 500  # number of testing points\n",
    "n_features = 25 # Number of features\n",
    "\n",
    "X_train, y_train, X_test, y_test = \\\n",
    "    generate_data(n_train=n_train,\n",
    "                  n_test=n_test,\n",
    "                  n_features=n_features,\n",
    "                  contamination=contamination,\n",
    "                  random_state=42)\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When you do unsupervised learning, it is always a safe step to standardize the predictors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train)    # Only the training data are used to fit the scaler transformation,\n",
    "X_train_scaled = scaler.transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)  # then the scaler is used to transform the test input data.\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot in a 2-D space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.054514</td>\n",
       "      <td>-0.744309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.514871</td>\n",
       "      <td>1.555876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.545867</td>\n",
       "      <td>-0.568265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.742949</td>\n",
       "      <td>-0.461278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.394277</td>\n",
       "      <td>0.338002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2\n",
       "0 -3.054514 -0.744309\n",
       "1 -2.514871  1.555876\n",
       "2 -3.545867 -0.568265\n",
       "3 -3.742949 -0.461278\n",
       "4 -2.394277  0.338002"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(2)\n",
    "x_pca = pca.fit_transform(X_train)\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "x_pca.columns=['PC1','PC2']\n",
    "x_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train[0], X_train[1], alpha=0.8) \n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder\n",
    "* You do not need the target variable to train the unsupervised learning model.\n",
    "* We will build three models: clf1, clf2, and clf3\n",
    "* clf1 has hidden_neurons = [25, 2, 2, 25]\n",
    "* clf2 has hidden_neurons = [25, 10, 2, 10, 25]\n",
    "* clf3 has hidden_neurons = [25, 15, 10, 2, 10, 15, 25])\n",
    "* The number of the hidden layers and the number of neutrons in a hidden layer: if there are too many hidden layers or too many neutrons, the model tends to overfit; otherwise the model tends to underfit.\n",
    "\n",
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 52        \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 25)                75        \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 25)                650       \n",
      "=================================================================\n",
      "Total params: 2,733\n",
      "Trainable params: 2,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 2s 30ms/step - loss: 5.1514 - val_loss: 5.1848\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.7174 - val_loss: 4.3492\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.4575 - val_loss: 3.8336\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.0460 - val_loss: 3.4819\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.7058 - val_loss: 3.2231\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.5113 - val_loss: 3.0156\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.3412 - val_loss: 2.8378\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.0089 - val_loss: 2.6711\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.0891 - val_loss: 2.5422\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.9651 - val_loss: 2.4333\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.9629 - val_loss: 2.3286\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.7431 - val_loss: 2.2337\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.6107 - val_loss: 2.1567\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.3960 - val_loss: 2.0944\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.5798 - val_loss: 2.0342\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.4668 - val_loss: 1.9799\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.5208 - val_loss: 1.9395\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.4224 - val_loss: 1.9065\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3742 - val_loss: 1.8814\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.2296 - val_loss: 1.8586\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.3463 - val_loss: 1.8343\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3295 - val_loss: 1.8154\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2474 - val_loss: 1.7986\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2975 - val_loss: 1.7841\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2274 - val_loss: 1.7715\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.1706 - val_loss: 1.7586\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.3170 - val_loss: 1.7438\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.3042 - val_loss: 1.7344\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.1956 - val_loss: 1.7244\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.2094 - val_loss: 1.7157\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1425 - val_loss: 1.7084\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1988 - val_loss: 1.7011\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.2436 - val_loss: 1.6936\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1416 - val_loss: 1.6865\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3382 - val_loss: 1.6783\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1892 - val_loss: 1.6711\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2130 - val_loss: 1.6639\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2104 - val_loss: 1.6589\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1262 - val_loss: 1.6533\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1560 - val_loss: 1.6483\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1130 - val_loss: 1.6429\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1535 - val_loss: 1.6388\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2090 - val_loss: 1.6316\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2053 - val_loss: 1.6253\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0924 - val_loss: 1.6201\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0322 - val_loss: 1.6176\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.1859 - val_loss: 1.6140\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0255 - val_loss: 1.6114\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.0567 - val_loss: 1.6084\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1206 - val_loss: 1.6044\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.1255 - val_loss: 1.6002\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.2053 - val_loss: 1.5963\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.0570 - val_loss: 1.5927\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.1488 - val_loss: 1.5903\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0560 - val_loss: 1.5879\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1080 - val_loss: 1.5850\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0776 - val_loss: 1.5823\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0138 - val_loss: 1.5791\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0657 - val_loss: 1.5758\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1322 - val_loss: 1.5712\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 1.2485 - val_loss: 1.5684\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1979 - val_loss: 1.5662\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9966 - val_loss: 1.5647\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1201 - val_loss: 1.5644\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9555 - val_loss: 1.5664\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9331 - val_loss: 1.5634\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0474 - val_loss: 1.5592\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0118 - val_loss: 1.5564\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0846 - val_loss: 1.5537\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9311 - val_loss: 1.5473\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0517 - val_loss: 1.5513\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.9198 - val_loss: 1.5503\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.9882 - val_loss: 1.5462\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9690 - val_loss: 1.5437\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0183 - val_loss: 1.5412\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0408 - val_loss: 1.5385\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2295 - val_loss: 1.5398\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0305 - val_loss: 1.5381\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0904 - val_loss: 1.5316\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1762 - val_loss: 1.5272\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.9462 - val_loss: 1.5220\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0186 - val_loss: 1.5197\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2040 - val_loss: 1.5187\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0327 - val_loss: 1.5203\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0326 - val_loss: 1.5205\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0526 - val_loss: 1.5266\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0978 - val_loss: 1.5322\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2877 - val_loss: 1.5276\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9682 - val_loss: 1.5220\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0884 - val_loss: 1.5216\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.1081 - val_loss: 1.5192\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.9371 - val_loss: 1.5177\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.0273 - val_loss: 1.5180\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.1222 - val_loss: 1.5194\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.1930 - val_loss: 1.5155\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9739 - val_loss: 1.5137\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.8629 - val_loss: 1.5136\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9814 - val_loss: 1.5099\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0393 - val_loss: 1.5131\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9519 - val_loss: 1.5115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(batch_size=32, contamination=0.1, dropout_rate=0.2, epochs=100,\n",
       "      hidden_activation='relu', hidden_neurons=[25, 2, 2, 25],\n",
       "      l2_regularizer=0.1,\n",
       "      loss=<function mean_squared_error at 0x7f8b33577d90>,\n",
       "      optimizer='adam', output_activation='sigmoid', preprocessing=True,\n",
       "      random_state=None, validation_size=0.1, verbose=1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = AutoEncoder(hidden_neurons =[25, 2, 2, 25])\n",
    "clf1.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learn how to produce outlier scores\n",
    "* \"decision_functions()\" predicts the outliers of a dataframe. A higher score means more abnormal. \n",
    "* The histogram below shows there are outliers. If we choose 1.0 to be the cutpoint, we can suggest those >=1.0 to be outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scores = clf1.decision_scores_ \n",
    "#y_train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scores = clf1.decision_scores_  # raw outlier scores\n",
    "\n",
    "# get the prediction on the test data\n",
    "y_test_pred = clf1.predict(X_test_scaled)  # outlier labels (0 or 1)\n",
    "# clf.decision_function: Predict raw anomaly score of X using the fitted detector.\n",
    "y_test_scores = clf1.decision_function(X_test_scaled)  # outlier scores\n",
    "\n",
    "y_test_pred = pd.Series(y_test_pred)\n",
    "y_test_scores = pd.Series(y_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    450\n",
       "1     50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.586388\n",
       "1       2.181094\n",
       "2       2.175470\n",
       "3       2.155936\n",
       "4       2.028136\n",
       "         ...    \n",
       "495    14.358992\n",
       "496    15.885574\n",
       "497    14.023825\n",
       "498    13.999738\n",
       "499    15.740541\n",
       "Length: 500, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ8klEQVR4nO3dfbycZX3n8c8XQgoKCIGTGB7kiI0o0BLYUwRRXrQBCwgk1kVBhaC0WevSlX3p6lG3LtZ2jW5lcdtqGxE5PBShIJIFtKSpiFieTmgEQmDDQyCRkBwiMUFUBH77x3UduTOZOTPnaeZcOd/36zWvuR/n/s0993zPdV/3zBlFBGZmVp4dOl2AmZmNjAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDvBRkLRC0nGdrmO8SfpLSc9IerrTtTQi6ThJa1tc9gJJV4xiW6slHZ+HJembkp6VdPdIH3Oik3SOpNs7XYdtzQHeQPVNWpm21UEcEYdExK1NHqdbUkiaMk6ljitJ+wMfAw6OiNeO0WOGpPXVfSJpiqQNkjr+xQRJu0u6SNKTkp6T9Ege37vO4m8DTgD2i4gjJU2VdG0+fqLVP/CSLpX0oqR9xvCpTAiS5kpaLmlzbggsldTd6bq2Bw7wwrXhD8MBwMaI2DDcFZvUtgk4qTJ+MvDscLcx1iRNBZYChwAnArsDbwU2AkfWWeUAYHVE/Lwy7XbgA0BLZyySXg28G/gZ8P4RFz8BSfpt4DJSI+A1wOuBrwIvj+E2JGlSZtmkfNJjpeZU+khJ/bmVsV7ShXmx2/L9ptyaO1rSDpL+u6QncqvzMkmvqTzu2XneRkl/XrOdC3IL7wpJm4Fz8rbvkLRJ0jpJf5uDaPDxQtJHJK2StEXS5yW9Ia+zWdI11eUr6x0PLAH2ybVfmqeflruPNkm6VdKba/bJJyXdB/x8iBC/HDi7Mn426Y1e3f4+khZL+mluBf9JZd4uudX6rKQHgd+rs+51kgYkPS7pvzSoo9bZwOuAd0XEgxHxckRsiIjPR8TNNds4F7gYODrvn89FxAsRcVFE3A681OI23036g/YXwPyabVyQX5/L8mu3QlJPZf6b82uwKc87rTLvUklflfTdXN+PJL02n008K+khSYdXlu+V9GjezoOS3lWvWEl/J+nLNdP+r6Tz6yw+G3g8IpZGsiUirouIJ/N6O0r6dGW7y5TO+pD0Vkn3SPpZvn9rZXu3SvorST8CngcOlPQmSUvy8fKwpPdUlj85P6ctkn4i6ePNXpQiRIRvdW7AauD4mmnnALfXWwa4AzgrD+8KHJWHu4EAplTW+xDwCHBgXvbbwOV53sHAc6RT86nAXwO/rmzngjw+j/QHeBfgPwBHAVPy9lYC51e2F8BiUmvyEOBXpFbmgaRW0YPA/Ab74ThgbWX8jcDPSd0GOwGfyM9lamWfLAf2B3Zp8JgBHAqsB/bIt/V5WlSW+wGptbYzKQgGgDl53kLgh8C0vK0HBuvM+2UZ8Nm8Dw8EHgP+sLIPr2hQ27eAvlaPjdpjoma5tcBxLRxrS4EvATOAF4EjKvMuAH5JOkPZEfgCcGeet1Pe95/Oz/MPgC3AQXn+pcAz+fjYGfhX4HHSH6kdgb8Evl/Z1unAPnn/vTe/zjNrnyfpTOQpYIc8vjcpRGfUeW4H5vr/N/D7wK418/8bcD9wECDgMGCv/Lo+C5xFOq7PzON75fVuBZ4kHc9TSMfxGuCDefyI/NwPycuvA96eh/es7uOSbx0vYKLe8pv0OVLLaPD2PI0D/Dbgc8DeNY/TzbYBvhT4SGX8IFIoTyGFzlWVea8CXmDrAL+tSe3nA9dXxgM4pjK+DPhkZfzLwEUNHus4tg7wPweuqYzvAPyEHFR5n3yoSX0B/Dap9fqfgA8DX8/TIi+zP6kFu1tlvS8Al+bhx4ATK/MW8EqAvwV4smabnwK+WdmHjQJ8CbCwhWNjTAKc1Np/GZidx/8Z+Epl/gXAv1TGDwZ+kYffTuqm2aEy/yrggjx8KfD1yrw/A1ZWxn8H2DREbcuBufWeJ6mRcEIePg+4eYjHOQq4hvQH+Je5rl3zvIcHt1GzzlnA3TXT7gDOycO3An9Rmfde4Ic1y/8D8D/y8JP5WNt9qNejtJu7UIY2LyL2GLwBHxli2XNJrdOH8uneKUMsuw/wRGX8CVJ4z8jz1gzOiIjnSf2vVWuqI5LeKOlGSU/nbpX/SWoVVa2vDP+izviuQ9TbsPaIeDnXs2+j+oZwGak1uE33Sd7OTyNiS2XaE5XtbLWf2Hp/HkDq9tk0eCO1Ume0UNNGYGaL9Y+Fs0ihujyPXwm8T9JOlWWqfenPAzvnrql9gDX5NRhU3UcwjNc9d90tr+yzQ9n2OBrUR+rnJ99f3ugJRsSdEfGeiOgi/dE5FvhMnr0/8Gid1WrfI7Dtc6u+/gcAb6l5zd8PDF54fzfpLOYJST+QdHSjekviAB8jEbEqIs4EpgNfBK5VujhV71MVT5EOuEGvI506ryed6u03OEPSLqRTyq02VzP+NeAhYFZE7E4KK4382Qxpq9olifQm/MkQ9TXyQ1JYziBd+KvdzjRJu1Wmva6ynXV5u9V5g9aQ+l33qNx2i4iTW6jpX4A/zK9dO5xN6r99WuljmheSQvOkoVcD0j7aX1tfwKvuo5ZJOoB0FnQeqZtiD1K3VKPj6ApgrqTDgDcD32llOxFxD6nL8NA8aQ3whjqL1r5HYNvnVj3O1gA/qHnNd42IPx3cbkTMJb0/v0M6IyieA3yMSPqApK7cGtqUJ79EOm18mdQXOOgq4L9Ker2kXUkt5qsj4kXgWuDUfAFnKqlbplkY7wZsBp6T9CbgT8fqedVxDfBOSXNyK/FjpD71fxvuA0U6tz0VOC0PV+etyY/5BUk7S/pd0lnOlZU6PiVpT0n7kboHBt0NbM4XU3fJF8oOlbTVhc4GLieFwXX5otgOkvbKF9pa+QOApN+StHMenZrr3+Y1zK3AN5D6lGfn26HAP1JzMbOBu0j91J+QtJPSRxZPJfXjD9dgY2Mg1/ZBXgnZbUTEWuAe0v66LiJ+UW85SW+T9CeSpufxNwGnAXfmRS4GPi9plpLflbQXcDPwRknvU/qI6XtJ3Uc3Nijpxrz8WXlf7CTp95Qu8k6V9H5Jr4mIX5PeK61eYJ7QHOBj50RghaTngK8AZ0TEL3MXyF8BP8qndkcBl5AO/NtIF5V+SQ6giFiRh79FamVuATaQQrKRjwPvy8t+Hbh67J9eEhEPk06Z/4Z0kehU4NSIeGGEj7ciP+d6ziRdQ3gKuJ7Un7kkz/sc6ZT6ceAWKqfwEfFSrmt2nv8MKSh+80mfIer5FXA86YxmCenNfjepVXxXi0/rYVL3xL6kPu1fsG1rElJI3xAR90fE04M30vFziqRpTWp9gRSGJ5Ge41eBsyPioRbrrD7Wg6RrIXeQzgR/B/hRk9X68nINu09IjZnTgPvze+N7pNfyS3n+haQ/xreQ9vU3SBe/NwKnkBoIG0kXy0+JiGca1L8FeAdwBul4eZp0JvxbeZGzgNW5i/HDvNL9UzTVNHxsgskt9E2k7pHHO1yO2W9IOpbUldJd0w9vbeIW+AQk6VRJr8r9sH9N+pjV6s5WZfaK3H32UeBih3fnOMAnprmk08CngFmk7hifKtmEoPTFrU2kC9AXdbSYSc5dKGZmhXIL3MysUG39D3l77713dHd3t3OTZmbFW7Zs2TP5i1BbaWuAd3d309/f385NmpkVT1Ltt1IBd6GYmRXLAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFahrgkg7KP7M0eNss6XxJ0/IvQK/K93u2o2AzM0uaBnhEPBwRsyNiNunXrZ8n/UP2XmBpRMwi/Uhv73gWOhLdvTfR3XtTp8swMxsXw+1CmQM8GhFPkP7laV+e3gfMG8O6zMysieEG+Bmk33MEmBER6wDy/fSxLMzMzIbWcoDnH9g9Dfin4WxA0gJJ/ZL6BwYGhlufmZk1MJwW+EnAvRGxPo+vlzQTIN9vqLdSRCyKiJ6I6Onq2ua/IZqZ2QgNJ8DP5JXuE4DFpF/VJt/fMFZFmZlZcy0FuKRXAScA365MXgicIGlVnrdw7MszM7NGWvpBh4h4HtirZtpG0qdSzMysA7bbb2L6899mtr3bbgPczGx75wA3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFCTIsD925hmtj2aFAFuZrY9coCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoVoKcEl7SLpW0kOSVko6WtI0SUskrcr3e453sWZm9opWW+BfAb4XEW8CDgNWAr3A0oiYBSzN42Zm1iZNA1zS7sCxwDcAIuKFiNgEzAX68mJ9wLzxKdHMzOpppQV+IDAAfFPSv0u6WNKrgRkRsQ4g30+vt7KkBZL6JfUPDAyMWeFmZpNdKwE+BTgC+FpEHA78nGF0l0TEoojoiYierq6uEZZpZma1WgnwtcDaiLgrj19LCvT1kmYC5PsN41OimZnV0zTAI+JpYI2kg/KkOcCDwGJgfp42H7hhXCo0M7O6prS43J8BV0qaCjwGfJAU/tdIOhd4Ejh9fEo0M7N6WgrwiFgO9NSZNWdMqzEzs5b5m5hmZoVygJuZFcoBbmZWqEkV4P5xYzPbnkyqADcz2544wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQLf2osaTVwBbgJeDFiOiRNA24GugGVgPviYhnx6dMMzOrNZwW+O9HxOyIGPx1+l5gaUTMApbmcTMza5PRdKHMBfrycB8wb9TVmJlZy1oN8ABukbRM0oI8bUZErAPI99PrrShpgaR+Sf0DAwOjr9jMzIAW+8CBYyLiKUnTgSWSHmp1AxGxCFgE0NPTEyOo0czM6mipBR4RT+X7DcD1wJHAekkzAfL9hvEq0szMttU0wCW9WtJug8PAO4AHgMXA/LzYfOCG8SrSzMy21UoXygzgekmDy/9jRHxP0j3ANZLOBZ4ETh+/Ms3MrFbTAI+Ix4DD6kzfCMwZj6LMzKw5fxPTzKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrVMsBLmlHSf8u6cY8Pk3SEkmr8v2e41emmZnVGk4L/KPAysp4L7A0ImYBS/O4mZm1SUsBLmk/4J3AxZXJc4G+PNwHzBvTyszMbEittsAvAj4BvFyZNiMi1gHk++n1VpS0QFK/pP6BgYHR1GpmZhVNA1zSKcCGiFg2kg1ExKKI6ImInq6urpE8hJmZ1TGlhWWOAU6TdDKwM7C7pCuA9ZJmRsQ6STOBDeNZqJmZba1pCzwiPhUR+0VEN3AG8K8R8QFgMTA/LzYfuGHcqhyG7t6b6O69qdNlmJmNu9F8DnwhcIKkVcAJedzMzNqklS6U34iIW4Fb8/BGYM7Yl2RmZq3wNzHNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK9SkDHB/2cfMtgeTMsDNzLYHDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQTQNc0s6S7pb0Y0krJH0uT58maYmkVfl+z/Ev18zMBrXSAv8V8AcRcRgwGzhR0lFAL7A0ImYBS/O4mZm1SdMAj+S5PLpTvgUwF+jL0/uAeeNRoJmZ1ddSH7ikHSUtBzYASyLiLmBGRKwDyPfTG6y7QFK/pP6BgYExKtvMzFoK8Ih4KSJmA/sBR0o6tNUNRMSiiOiJiJ6urq4RlmlmZrWG9SmUiNgE3AqcCKyXNBMg328Y6+LMzKyxVj6F0iVpjzy8C3A88BCwGJifF5sP3DBONZqZWR1TWlhmJtAnaUdS4F8TETdKugO4RtK5wJPA6eNYp5mZ1Wga4BFxH3B4nekbgTnjUZSZmTXnb2KamRXKAW5mVigHuJlZoVq5iFmE7t6bOl2CmVlbuQVuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhZrUAd7de5P/h4qZFWtSB7iZWckc4GZmhXKAm5kVygFuZlaopgEuaX9J35e0UtIKSR/N06dJWiJpVb7fc/zLNTOzQa38Is+LwMci4l5JuwHLJC0BzgGWRsRCSb1AL/DJ8Su1Pn+KxMwmq6Yt8IhYFxH35uEtwEpgX2Au0JcX6wPmjVONZmZWx7D6wCV1A4cDdwEzImIdpJAHpjdYZ4Gkfkn9AwMDoyzXzMwGtRzgknYFrgPOj4jNra4XEYsioicierq6ukZSo5mZ1dFSgEvaiRTeV0bEt/Pk9ZJm5vkzgQ3jU6KZmdXTyqdQBHwDWBkRF1ZmLQbm5+H5wA1jX56ZmTXSyqdQjgHOAu6XtDxP+zSwELhG0rnAk8Dp41KhmZnV1TTAI+J2QA1mzxnbcszMrFX+Jib+r4RmViYHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgFf5lHjMriQPczKxQTQNc0iWSNkh6oDJtmqQlklbl+z3Ht0wzM6vVSgv8UuDEmmm9wNKImAUszeNmZtZGTQM8Im4DflozeS7Ql4f7gHljW5aZmTUz0j7wGRGxDiDfTx+7kszMrBXjfhFT0gJJ/ZL6BwYGxntzZmaTxkgDfL2kmQD5fkOjBSNiUUT0RERPV1fXCDdnZma1Rhrgi4H5eXg+cMPYlGNmZq1q5WOEVwF3AAdJWivpXGAhcIKkVcAJedzMzNpoSrMFIuLMBrPmjHEtZmY2DP4mpplZoRzgZmaFcoCbmRWqaR/4ROX/Gmhmk51b4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaGK+yKPv8BjNj4G31urF75zQj2WNeYWuJlZoRzgZmaFcoCb2bB19940qu7M0a5viQPczKxQDnAzs0IV9ykUs8lotJ/q6O69qaOfCBmPT6XUdsFMxk+8uAVuZlYoB7iZWaFG1YUi6UTgK8COwMURsXBMqqqjnVesa0/3/KUEa7ex6DJptn6j91Sz91r1MZst28r82vdZ7XZG+2mXemr3S6P9VV2/1deinfkx4ha4pB2BvwNOAg4GzpR08FgVZmZmQxtNF8qRwCMR8VhEvAB8C5g7NmWZmVkzioiRrSj9R+DEiPjjPH4W8JaIOK9muQXAgjx6EPDwyMsdd3sDz3S6iGEorV4or+bS6gXX3A7trveAiOiqnTiaPnDVmbbNX4OIWAQsGsV22kZSf0T0dLqOVpVWL5RXc2n1gmtuh4lS72i6UNYC+1fG9wOeGl05ZmbWqtEE+D3ALEmvlzQVOANYPDZlmZlZMyPuQomIFyWdB/wz6WOEl0TEijGrrDOK6OqpKK1eKK/m0uoF19wOE6LeEV/ENDOzzvI3Mc3MCuUANzMr1KQKcEn7S/q+pJWSVkj6aJ1ljpP0M0nL8+2znai1pqbVku7P9fTXmS9J/0fSI5Luk3REJ+qs1HNQZf8tl7RZ0vk1y3R0P0u6RNIGSQ9Upk2TtETSqny/Z4N1T5T0cN7fvR2u+X9Jeii/7tdL2qPBukMeQ22s9wJJP6m87ic3WHci7eOrK/WulrS8wbpt38dExKS5ATOBI/LwbsD/Aw6uWeY44MZO11pT02pg7yHmnwx8l/TZ/KOAuzpdc6W2HYGnSV9EmDD7GTgWOAJ4oDLtS0BvHu4Fvtjg+TwKHAhMBX5cewy1ueZ3AFPy8Bfr1dzKMdTGei8APt7CMTNh9nHN/C8Dn50o+3hStcAjYl1E3JuHtwArgX07W9WYmAtcFsmdwB6SZna6qGwO8GhEPNHpQqoi4jbgpzWT5wJ9ebgPmFdn1Y79C4l6NUfELRHxYh69k/R9jAmhwT5uxYTax4MkCXgPcFU7amnFpArwKkndwOHAXXVmHy3px5K+K+mQ9lZWVwC3SFqW/zVBrX2BNZXxtUycP0xn0PiAn2j7eUZErIP0xx6YXmeZibyvP0Q6E6un2THUTuflLp9LGnRTTdR9/HZgfUSsajC/7ft4Uga4pF2B64DzI2Jzzex7Saf7hwF/A3ynzeXVc0xEHEH6z4//WdKxNfNb+rcG7Za/4HUa8E91Zk/E/dyKibqvPwO8CFzZYJFmx1C7fA14AzAbWEfqkqg1IfcxcCZDt77bvo8nXYBL2okU3ldGxLdr50fE5oh4Lg/fDOwkae82l1lb01P5fgNwPekUs2qi/luDk4B7I2J97YyJuJ+B9YNdT/l+Q51lJty+ljQfOAV4f+TO2FotHENtERHrI+KliHgZ+HqDOibiPp4C/BFwdaNlOrGPJ1WA5z6sbwArI+LCBsu8Ni+HpCNJ+2hj+6rcpp5XS9ptcJh00eqBmsUWA2fnT6McBfxssCugwxq2WCbafs4WA/Pz8HzghjrLTKh/IaH0oyqfBE6LiOcbLNPKMdQWNddm3tWgjgm1j7PjgYciYm29mR3bx+28YtrpG/A20qnYfcDyfDsZ+DDw4bzMecAK0pXvO4G3drjmA3MtP851fSZPr9Ys0o9rPArcD/RMgH39KlIgv6YybcLsZ9IflnXAr0ktvnOBvYClwKp8Py0vuw9wc2Xdk0mfYHp08PXoYM2PkPqLB4/nv6+tudEx1KF6L8/H6H2kUJ450fdxnn7p4LFbWbbj+9hfpTczK9Sk6kIxM9ueOMDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK9T/B4jTj/9tLlqcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_test_scores, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram for Model Clf1 Anomaly Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will identify the outliers as a cluster and demonstrate the X attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    450\n",
       "1     50\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = X_test_scaled.copy()\n",
    "df_test['score'] = y_test_scores\n",
    "df_test['cluster'] = np.where(df_test['score']<4, 0, 1)\n",
    "df_test['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the outliers\n",
    "* We recommend observations in Cluster 1 to be outliers. \n",
    "* The attributes of Cluster 1 are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.284756</td>\n",
       "      <td>0.233752</td>\n",
       "      <td>0.213252</td>\n",
       "      <td>0.282784</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>0.268499</td>\n",
       "      <td>0.256723</td>\n",
       "      <td>0.330233</td>\n",
       "      <td>0.307315</td>\n",
       "      <td>0.264452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274579</td>\n",
       "      <td>0.268014</td>\n",
       "      <td>0.261233</td>\n",
       "      <td>0.300980</td>\n",
       "      <td>0.257770</td>\n",
       "      <td>0.306561</td>\n",
       "      <td>0.246576</td>\n",
       "      <td>0.235519</td>\n",
       "      <td>0.266344</td>\n",
       "      <td>1.968473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.405669</td>\n",
       "      <td>-2.351177</td>\n",
       "      <td>-2.171415</td>\n",
       "      <td>-1.715717</td>\n",
       "      <td>-2.212427</td>\n",
       "      <td>-2.263555</td>\n",
       "      <td>-2.649875</td>\n",
       "      <td>-2.384148</td>\n",
       "      <td>-2.375294</td>\n",
       "      <td>-2.013565</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.580048</td>\n",
       "      <td>-2.536069</td>\n",
       "      <td>-2.122499</td>\n",
       "      <td>-2.475651</td>\n",
       "      <td>-2.708152</td>\n",
       "      <td>-3.006297</td>\n",
       "      <td>-2.566102</td>\n",
       "      <td>-2.784837</td>\n",
       "      <td>-2.326757</td>\n",
       "      <td>14.613177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "cluster                                                                         \n",
       "0        0.284756  0.233752  0.213252  0.282784  0.304749  0.268499  0.256723   \n",
       "1       -2.405669 -2.351177 -2.171415 -1.715717 -2.212427 -2.263555 -2.649875   \n",
       "\n",
       "                7         8         9  ...        16        17        18  \\\n",
       "cluster                                ...                                 \n",
       "0        0.330233  0.307315  0.264452  ...  0.274579  0.268014  0.261233   \n",
       "1       -2.384148 -2.375294 -2.013565  ... -2.580048 -2.536069 -2.122499   \n",
       "\n",
       "               19        20        21        22        23        24      score  \n",
       "cluster                                                                         \n",
       "0        0.300980  0.257770  0.306561  0.246576  0.235519  0.266344   1.968473  \n",
       "1       -2.475651 -2.708152 -3.006297 -2.566102 -2.784837 -2.326757  14.613177  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 25)                275       \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 25)                650       \n",
      "=================================================================\n",
      "Total params: 3,187\n",
      "Trainable params: 3,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 22ms/step - loss: 4.1126 - val_loss: 3.2562\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.6357 - val_loss: 2.8267\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.7578 - val_loss: 2.6095\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.6396 - val_loss: 2.4393\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.2414 - val_loss: 2.2943\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.2729 - val_loss: 2.1758\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.1520 - val_loss: 2.0721\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.8079 - val_loss: 1.9748\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.1150 - val_loss: 1.8832\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.6615 - val_loss: 1.8042\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.8610 - val_loss: 1.7321\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.9369 - val_loss: 1.6742\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.6549 - val_loss: 1.6284\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.6566 - val_loss: 1.5890\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.5587 - val_loss: 1.5567\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.4783 - val_loss: 1.5280\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.5371 - val_loss: 1.5033\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.4277 - val_loss: 1.4821\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.6546 - val_loss: 1.4610\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.4750 - val_loss: 1.4429\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.5080 - val_loss: 1.4266\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2751 - val_loss: 1.4123\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.3695 - val_loss: 1.3982\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1870 - val_loss: 1.3841\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.4203 - val_loss: 1.3720\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.1901 - val_loss: 1.3615\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1553 - val_loss: 1.3521\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1531 - val_loss: 1.3427\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3291 - val_loss: 1.3336\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2822 - val_loss: 1.3252\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3209 - val_loss: 1.3166\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1312 - val_loss: 1.3083\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2961 - val_loss: 1.3006\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2801 - val_loss: 1.2936\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2968 - val_loss: 1.2872\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3317 - val_loss: 1.2807\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.3155 - val_loss: 1.2750\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3200 - val_loss: 1.2692\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0722 - val_loss: 1.2635\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3089 - val_loss: 1.2587\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0912 - val_loss: 1.2540\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2717 - val_loss: 1.2496\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2063 - val_loss: 1.2442\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1550 - val_loss: 1.2397\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0532 - val_loss: 1.2360\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1022 - val_loss: 1.2328\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1370 - val_loss: 1.2284\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1529 - val_loss: 1.2242\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2028 - val_loss: 1.2207\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9975 - val_loss: 1.2172\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1442 - val_loss: 1.2143\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0621 - val_loss: 1.2111\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0542 - val_loss: 1.2076\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0502 - val_loss: 1.2044\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.2890 - val_loss: 1.2014\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0284 - val_loss: 1.1977\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.1090 - val_loss: 1.1958\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0802 - val_loss: 1.1939\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1911 - val_loss: 1.1907\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0704 - val_loss: 1.1894\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0685 - val_loss: 1.1877\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1886 - val_loss: 1.1845\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1815 - val_loss: 1.1813\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0866 - val_loss: 1.1785\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0732 - val_loss: 1.1764\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0553 - val_loss: 1.1764\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0720 - val_loss: 1.1748\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0863 - val_loss: 1.1721\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1199 - val_loss: 1.1711\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0115 - val_loss: 1.1687\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1136 - val_loss: 1.1689\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2041 - val_loss: 1.1674\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3039 - val_loss: 1.1641\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1290 - val_loss: 1.1638\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9681 - val_loss: 1.1638\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1194 - val_loss: 1.1614\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2103 - val_loss: 1.1600\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0276 - val_loss: 1.1585\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1998 - val_loss: 1.1568\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2580 - val_loss: 1.1553\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0648 - val_loss: 1.1533\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0718 - val_loss: 1.1517\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9448 - val_loss: 1.1510\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1793 - val_loss: 1.1489\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1211 - val_loss: 1.1483\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0812 - val_loss: 1.1474\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.9331 - val_loss: 1.1496\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.0686 - val_loss: 1.1458\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0857 - val_loss: 1.1420\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.9439 - val_loss: 1.1420\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0673 - val_loss: 1.1422\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.9538 - val_loss: 1.1388\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0101 - val_loss: 1.1401\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.0169 - val_loss: 1.1403\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0354 - val_loss: 1.1385\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.8744 - val_loss: 1.1371\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0209 - val_loss: 1.1368\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2706 - val_loss: 1.1356\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0285 - val_loss: 1.1353\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0886 - val_loss: 1.1339\n"
     ]
    }
   ],
   "source": [
    "clf2 = AutoEncoder(hidden_neurons =[25, 10,2, 10, 25])\n",
    "clf2.fit(X_train_scaled)\n",
    "\n",
    "# clf.decision_function: Predict raw anomaly score of X using the fitted detector.\n",
    "y_test_scores = clf2.decision_function(X_test_scaled)  # outlier scores\n",
    "y_test_scores = pd.Series(y_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAaD0lEQVR4nO3df7icZX3n8fcHAgvKr4ScxPBDjrQRBCqBPUV+KBdtwIYIhO4WBRWOis3aLl3YS1eOurVQ2zW6ldXtWrsBMUegCIJIFtSSpiLaBeSERiAGNoCBREJyCGJAUAS++8d9H3kymTkz5+ScmXPnfF7XNdc8P+f5zj3PfOaZe56ZUURgZmbl2anTBZiZ2eg4wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUA3w6SVkk6qdN1jDdJfyXpKUlPdrqWRiSdJGl9i8teIunq7djWWkkn52FJ+oqkn0n64Whvc6KT9D5JP+h0HbY1B3gD1SdpZdpWO3FEHB4Rtze5nW5JIWnKOJU6riQdCHwYOCwiXjdGtxmSNlbbRNIUSZskdfyLCZL2kvR5SY9Lek7Sw3l8ep3F3wqcAhwQEcdIOlbSMklPSxqU9HVJs1rY5hJJL0nab8zvUIdJWiBppaQt+UBguaTuTte1I3CAF64NLwwHAZsjYtNIV2xS2zPAqZXx+cDPRrqNsSZpV2A5cDgwD9gLOB7YDBxTZ5WDgLUR8Ys8PhVYDHTnec8CX2myzdcC/x74OfCe7b4TE4ik3wa+SjoI2Bt4A/B3wCtjuA1JmpxZFhG+1LkAa4GTa6a9D/hBvWVIT+4BYAuwEbgsT38cCOC5fDmO9ML5X4HHgE2kHXzvyu2el+dtBv68ZjuXADcAV+dtfTBv+05SKG4A/hewa+X2AvhTYA0pUD4F/FZeZwtwfXX5ynonAy+QnmzPAUvy9DOAVXl7twNvqmmTi4H7gF8BU+rcbuT7//XKtBuAT6Rd8jfT9gOWAk8DDwN/XJm3O7CEFPo/Bv4LsL5m3RuBQeAnwH+qzLsEuLrB4/7B/Pjt0WzfAM4Hfgm8nNvn0jrLHg0822RfOw9YB1wIPFAz75L8+Hw1P3argJ7K/Dflx+CZPO+MyrwlpLD8dq7vX4DXAZ/P7fYgcFRl+T7gkbydHwN/WG/fB74IfK6mzv8DXFTnvv0RsHKY+74z8PHKdlcAB+Z5xwP3kF7Y7gGOr6x3O/DX+T69APw2cCiwLO8vDwHvrCw/P9+nZ4GfAh/pdMaMxaXjBUzUCyMP8DuBc/PwHsCxebibFFhTKut9gBRIB+dlvwFclecdlp9sbwV2Bf4G+DVbB/ivgTNJLwS7A/8WOBaYkre3uvpkyttfSjqaPJwUrMvz9vfOO3Zvg3Y4ia2D8Y3AL0jdBrsAH833ZddKm6wEDgR2b3CbARxBCsp98mVjnhaV5b5HCqDdgDmkMJ6b5y0Cvg9My9t6YKjO3C4rgE/mNjwYeBT4g0obNgrwrwH9re4btftEnWUvAu5qcnvLgc8CM4GXgKMr8y4hvUjMJ4Xdp4duL7f/w6QA3BX4fVJAHZLnLwGeyvvHbsA/k17Mzsu39VfAdyvbOov0wrcT8K78OM+qvZ+kA4YngJ3y+HTgeWBmnft2cK7/fwC/R80LI+mF937gEEDAkcC++XH9GXAuab8+J4/vm9e7nXRwdHievzfpRfD9efzofN8Pz8tvAN6Wh6dW27jkS8cLmKiX/CR9jnRkM3R5nsYBfgdwKTC95na62TbAlwN/Whk/hBTKU0ihc21l3muAF9k6wO9oUvtFwE2V8QBOqIyvAC6ujH8O+HyD2zqJrQP8z4HrK+M7kY5oTqq0yQea1BekI6YrgP8AfAi4PE+LvMyBpCPbPSvrfZpX3wU8CsyrzFvIqwH+FuDxmm1+DPhKpQ0bBfgyYFEL+0bTAAfeTDoafNswt/V60jucOXn8H4EvVOZfAvxTZfww4IU8/DbgSXKQ5mnXApfk4SXA5ZV5fwasroz/DvDMMLWtBBbUu5+kg4RT8vAFwLeGuZ1jSe8iBklhvoQc5KQj5QV11jkX+GHNtDuB9+Xh24G/rMx7F/D9muX/N/AXefjxvK/tNdxjW9plcvYbte7MiNhn6ELqhmjkfNLR6YOS7pF02jDL7kfqIhnyGCm8Z+Z564ZmRMTzpK6UqnXVEUlvlHSLpCclbQH+G+moqGpjZfiFOuN7DFNvw9oj4pVcz/6N6hvGV0lHg+fl4drtPB0Rz1amPVbZzlbtxNbteRCwn6Rnhi6ko9SZLdS0GWj6oWMzue/328CFEfH9YRY9lxSqK/P4NcC7Je1SWaZ69s/zwG7584X9gHX5MRhSbSMYweMu6bz8YeNQmx3BtvvRkH7gvXn4vcBVje5gRNwVEe+MiC7Si86JpO4ySC/Uj9RZrfY5Atvet+rjfxDwlprH/D2kLiNInzHMBx6T9D1JxzWqtyQO8DESEWsi4hxgBvAZ4Ib84VTUWfwJ0g435PWkt84bSW/1DhiaIWl30lvKrTZXM/4lUn/m7IjYixRWGv29GdZWtUsS6Un402Hqa+T7pLCcCdSeovYEME3SnpVpr69sZ0PebnXekHXAT6ovvhGxZ0TMb6GmfwL+ID92oyLpoHw7n4qIhsGWnQccnF98nwQuI4XmqcOvBqQ2OrDmA7xqG4205stJR9P75gOWB2i8H10NLJB0JKkf/putbCci7iF1GR6RJ60jfR5Tq/Y5Atvet+p+tg74Xs1jvkdE/MnQdiNiAen5+U3SO4LiOcDHiKT3SurKR0PP5Mkvk942vkLqCxxyLfCfJb1B0h6kI+brIuIl0od5p0s6Pp8RcSnNw3hP0oeRz0k6FPiTsbpfdVwPvEPS3HyU+GFSn/r/HekNRXpvezrpg7eombcu3+anJe0m6c2kdznXVOr4mKSpkg4gdQ8M+SGwRdLFknaXtLOkIyT9bgtlXUUKgxslHSppJ0n7Svq4pKYvAJL2J/U1fzEi/r7JsseRwusYUh//HFKw/QPQ20Ktd5P6qT8qaRel7yScTurHH6mhg43BXNv7eTVktxER60kfLF4F3BgRL9RbTtJbJf2xpBl5/FDSh+B35UWuAD4laXY+m+TNkvYFvgW8UdK78ymm7yJ1H93SoKRb8vLn5rbYRdLvSnqTpF0lvUfS3hHxa9Jz5eWRNM5E5QAfO/OAVZKeA74AnB0Rv8xdIH8N/Et+a3cscCVpx7+D9KHSL8kBFBGr8vDXSEeZz5LOVPnVMNv+CPDuvOzlwHVjf/eSiHiI9Jb5b0kfEp0OnB4RL47y9lbl+1zPOaTPEJ4AbiL1Zy7L8y4lvaX+CXAblbfwEfFyrmtOnv8UKSj2bqGeX5HOMHmQ1B++hfSCMJ0UmM18kPRi/Rf5HPLn8j5RTy9wc0TcHxFPDl1I+89pkqY1qfVFUhiemu/j3wHnRcSDLdRZe1s/Jn0WcifpneDvkM7wGE5/Xm64dxnP5Brvz+3wHdJj+dk8/zLSi/FtpLb+MunD783AaaQDhM2kD8tPi4inGtT/LPB24GzS/vIk6Z3wv8mLnAuszV2MH+LV7p+iqebAxyaYfIT+DKl75CcdLsfsNySdSOpK6a7ph7c28RH4BCTpdEmvyf2wf0M6zWptZ6sye1XuPrsQuMLh3TkO8IlpAelt4BPAbFJ3jN8q2YQg6U2kd4WzSF8Ksg5xF4qZWaF8BG5mVqi2/kLe9OnTo7u7u52bNDMr3ooVK57KX4TaSlsDvLu7m4GBgXZu0syseJJqv5UKuAvFzKxYDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I1DXBJh+QfeR+6bJF0kaRpSv++vSZfT21HwWZmljQN8Ih4KCLmRMQc0n/rPU/6Ocg+YHlEzCb9RVjfeBZqZmZbG2kXylzgkYh4jPSDS/15ej/pT3bNzKxNRhrgZ5P+TQbSP1BvAMjXM+qtIGmhpAFJA4ODg6OvdBS6+26lu+/Wtm7TzKxdWg7w/PdeZwBfH8kGImJxRPRERE9X1zZf5Tczs1EayRH4qcC9ETH0r9YbJc0CyNebxro4MzNrbCQBfg6vdp8ALOXVP17tBW4eq6LMzKy5lgJc0muAU4BvVCYvAk6RtCbPWzT25ZmZWSMt/Zxs/mf1fWumbSadlWJmZh3Q1t8DbxefeWJmk4G/Sm9mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRVqUgS4f1bWzHZEkyLAzcx2RA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCtfqv9PtIukHSg5JWSzpO0jRJyyStyddTx7tYMzN7VatH4F8AvhMRhwJHAquBPmB5RMwGludxMzNrk6YBLmkv4ETgywAR8WJEPAMsAPrzYv3AmeNTopmZ1dPKEfjBwCDwFUn/KukKSa8FZkbEBoB8PaPeypIWShqQNDA4ODhmhZuZTXatBPgU4GjgSxFxFPALRtBdEhGLI6InInq6urpGWaaZmdVqJcDXA+sj4u48fgMp0DdKmgWQrzeNT4lmZlZP0wCPiCeBdZIOyZPmAj8GlgK9eVovcPO4VGhmZnVNaXG5PwOukbQr8CjwflL4Xy/pfOBx4KzxKdHMzOppKcAjYiXQU2fW3DGtxszMWjapvonp/8Y0sx3JpApwM7MdiQPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCtXSv9JLWgs8C7wMvBQRPZKmAdcB3cBa4J0R8bPxKdPMzGqN5Aj89yJiTkT05PE+YHlEzAaW53EzM2uT7elCWQD05+F+4MztrsbMzFrWaoAHcJukFZIW5mkzI2IDQL6eUW9FSQslDUgaGBwc3P6KzcwMaLEPHDghIp6QNANYJunBVjcQEYuBxQA9PT0xihrNzKyOlo7AI+KJfL0JuAk4BtgoaRZAvt40XkWamdm2mga4pNdK2nNoGHg78ACwFOjNi/UCN49XkWZmtq1WulBmAjdJGlr+HyLiO5LuAa6XdD7wOHDW+JVpZma1mgZ4RDwKHFln+mZg7ngUZWZmzfmbmGZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaFaDnBJO0v6V0m35PFpkpZJWpOvp45fmWZmVmskR+AXAqsr433A8oiYDSzP42Zm1iYtBbikA4B3AFdUJi8A+vNwP3DmmFZmZmbDavUI/PPAR4FXKtNmRsQGgHw9o96KkhZKGpA0MDg4uD21mplZRdMAl3QasCkiVoxmAxGxOCJ6IqKnq6trNDdhZmZ1TGlhmROAMyTNB3YD9pJ0NbBR0qyI2CBpFrBpPAs1M7OtNT0Cj4iPRcQBEdENnA38c0S8F1gK9ObFeoGbx61KMzPbxvacB74IOEXSGuCUPG5mZm3SShfKb0TE7cDteXgzMHfsSzIzs1bscN/E7O67tdMlmJm1xQ4X4GZmk4UD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCTcoA7+671b+ZYmbFm5QBbma2I3CAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaGaBrik3ST9UNKPJK2SdGmePk3SMklr8vXU8S/XzMyGtHIE/ivg9yPiSGAOME/SsUAfsDwiZgPL87iZmbVJ0wCP5Lk8uku+BLAA6M/T+4Ezx6NAMzOrr6U+cEk7S1oJbAKWRcTdwMyI2ACQr2c0WHehpAFJA4ODg2NUtpmZtRTgEfFyRMwBDgCOkXREqxuIiMUR0RMRPV1dXaMs08zMao3oLJSIeAa4HZgHbJQ0CyBfbxrr4szMrLFWzkLpkrRPHt4dOBl4EFgK9ObFeoGbx6lGMzOrY0oLy8wC+iXtTAr86yPiFkl3AtdLOh94HDhrHOs0M7MaTQM8Iu4DjqozfTMwdzyKMjOz5vxNTDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK1cp54EXo7ru10yWYmbWVj8DNzArlADczK9SkDvDuvlvd9WJmxZrUAW5mVjIHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoZoGuKQDJX1X0mpJqyRdmKdPk7RM0pp8PXX8yzUzsyGt/JzsS8CHI+JeSXsCKyQtA94HLI+IRZL6gD7g4vErtT7/lomZTVZNj8AjYkNE3JuHnwVWA/sDC4D+vFg/cOY41WhmZnWMqA9cUjdwFHA3MDMiNkAKeWDGmFdnZmYNtRzgkvYAbgQuiogtI1hvoaQBSQODg4OjqdHMzOpoKcAl7UIK72si4ht58kZJs/L8WcCmeutGxOKI6ImInq6urrGo2czMaO0sFAFfBlZHxGWVWUuB3jzcC9w89uWZmVkjrZyFcgJwLnC/pJV52seBRcD1ks4HHgfOGpcKzcysrqYBHhE/ANRg9tyxLcfMzFrlb2KamRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoVr5Q4cdXnffrb8ZXrvoHR2sxMysdT4CNzMrlAPczKxQDnAzs0I5wM3MCuUANzMrVNMAl3SlpE2SHqhMmyZpmaQ1+Xrq+JZpZma1WjkCXwLMq5nWByyPiNnA8jxuZmZt1DTAI+IO4OmayQuA/jzcD5w5tmWZmVkzo+0DnxkRGwDy9YxGC0paKGlA0sDg4OAoN2dmZrXG/UPMiFgcET0R0dPV1TXemzMzmzRGG+AbJc0CyNebxq4kMzNrxWgDfCnQm4d7gZvHphwzM2tVK6cRXgvcCRwiab2k84FFwCmS1gCn5HEzM2ujpr9GGBHnNJg1d4xrMTOzESj252SrPwFrZjYZ+av0ZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgNbr7bvWXhMysCA5wM7NCOcDNzApV3G+huHvDbOIYej6uXfSOYafZ+PARuJlZoRzgZmaFcoCbWbEme5eqA9zMrFAOcDOzQhV3ForZjm68zuKovd1G3Q/DbXcktTXaXu261ek+g2VkfARuZlYoB7iZWaG2qwtF0jzgC8DOwBURsWhMqqqj0582+62dTQTN9sNW9tNmz6Xq/PHY35t1pbSyTnXZZl01tbc73JeOGi07XLuOxWMyWqM+Ape0M/BF4FTgMOAcSYeNVWFmZja87elCOQZ4OCIejYgXga8BC8amLDMza0YRMboVpT8C5kXEB/P4ucBbIuKCmuUWAgvz6CHAQ6Mvd9xNB57qdBEjUFq9UF7NpdUL5dVcWr3Q/poPioiu2onb0weuOtO2eTWIiMXA4u3YTttIGoiInk7X0arS6oXyai6tXiiv5tLqhYlT8/Z0oawHDqyMHwA8sX3lmJlZq7YnwO8BZkt6g6RdgbOBpWNTlpmZNTPqLpSIeEnSBcA/kk4jvDIiVo1ZZZ1RRFdPRWn1Qnk1l1YvlFdzafXCBKl51B9implZZ/mbmGZmhXKAm5kValIFuKQDJX1X0mpJqyRdWGeZkyT9XNLKfPlkJ2qtqWmtpPtzPQN15kvS/5T0sKT7JB3diTpzLYdU2m6lpC2SLqpZpuNtLOlKSZskPVCZNk3SMklr8vXUBuvOk/RQbu++Dtf83yU9mB/3myTt02DdYfehNtZ7iaSfVh77+Q3WbXsbN6j3ukqtayWtbLBu29sXgIiYNBdgFnB0Ht4T+H/AYTXLnATc0ulaa2paC0wfZv584Nukc/OPBe7udM25rp2BJ0lfQphQbQycCBwNPFCZ9lmgLw/3AZ9pcJ8eAQ4GdgV+VLsPtbnmtwNT8vBn6tXcyj7UxnovAT7Swn7T9jauV2/N/M8Bn5wo7RsRk+sIPCI2RMS9efhZYDWwf2erGhMLgK9Gchewj6RZnS4KmAs8EhGPdbqQWhFxB/B0zeQFQH8e7gfOrLNqx35Col7NEXFbRLyUR+8ifR9jQmjQxq3oSBsPV68kAe8Erh3vOkZiUgV4laRu4Cjg7jqzj5P0I0nflnR4eyurK4DbJK3IP01Qa39gXWV8PRPjhelsGu/wE62NAWZGxAZIL/bAjDrLTNS2BvgA6Z1YPc32oXa6IHf5XNmgm2oitvHbgI0RsabB/I6076QMcEl7ADcCF0XElprZ95Le8h8J/C3wzTaXV88JEXE06Zcf/6OkE2vmt/SzBu2Uv9x1BvD1OrMnYhu3asK1NYCkTwAvAdc0WKTZPtQuXwJ+C5gDbCB1S9SaiG18DsMffXekfSddgEvahRTe10TEN2rnR8SWiHguD38L2EXS9DaXWVvTE/l6E3AT6S1m1UT8WYNTgXsjYmPtjInYxtnGoa6nfL2pzjITrq0l9QKnAe+J3CFbq4V9qC0iYmNEvBwRrwCXN6hjQrWxpCnAvwOua7RMp9p3UgV47sf6MrA6Ii5rsMzr8nJIOobURpvbV+U29bxW0p5Dw6QPrR6oWWwpcF4+G+VY4OdDXQEd1PCIZaK1ccVSoDcP9wI311lmQv2EhNKfqlwMnBERzzdYppV9qC1qPpv5wwZ1TKg2Bk4GHoyI9fVmdrR92/2paScvwFtJb8XuA1bmy3zgQ8CH8jIXAKtIn3zfBRzf4ZoPzrX8KNf1iTy9WrNIf67xCHA/0NPhml9DCuS9K9MmVBuTXlw2AL8mHfGdD+wLLAfW5Otpedn9gG9V1p1POoPpkaHHo4M1P0zqLx7an/++tuZG+1CH6r0q76P3kUJ51kRp43r15ulLhvbdyrIdb9+I8FfpzcxKNam6UMzMdiQOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK9f8BH4rmJjcUxDQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_test_scores, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram for Model Clf2 Anomaly Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    450\n",
       "1     50\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = X_test.copy()\n",
    "df_test['score'] = y_test_scores\n",
    "df_test['cluster'] = np.where(df_test['score']<4, 0, 1)\n",
    "df_test['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.248812</td>\n",
       "      <td>0.235591</td>\n",
       "      <td>0.254013</td>\n",
       "      <td>0.239429</td>\n",
       "      <td>0.239101</td>\n",
       "      <td>0.255499</td>\n",
       "      <td>0.257207</td>\n",
       "      <td>0.24438</td>\n",
       "      <td>0.248004</td>\n",
       "      <td>0.251948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247737</td>\n",
       "      <td>0.251469</td>\n",
       "      <td>0.259140</td>\n",
       "      <td>0.249625</td>\n",
       "      <td>0.235669</td>\n",
       "      <td>0.244511</td>\n",
       "      <td>0.237602</td>\n",
       "      <td>0.246901</td>\n",
       "      <td>0.249373</td>\n",
       "      <td>2.713394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.239305</td>\n",
       "      <td>-2.120321</td>\n",
       "      <td>-2.286113</td>\n",
       "      <td>-2.154863</td>\n",
       "      <td>-2.151912</td>\n",
       "      <td>-2.299489</td>\n",
       "      <td>-2.314860</td>\n",
       "      <td>-2.19942</td>\n",
       "      <td>-2.232040</td>\n",
       "      <td>-2.267535</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.229637</td>\n",
       "      <td>-2.263223</td>\n",
       "      <td>-2.332263</td>\n",
       "      <td>-2.246622</td>\n",
       "      <td>-2.121021</td>\n",
       "      <td>-2.200595</td>\n",
       "      <td>-2.138417</td>\n",
       "      <td>-2.222110</td>\n",
       "      <td>-2.244355</td>\n",
       "      <td>13.503675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "cluster                                                                         \n",
       "0        0.248812  0.235591  0.254013  0.239429  0.239101  0.255499  0.257207   \n",
       "1       -2.239305 -2.120321 -2.286113 -2.154863 -2.151912 -2.299489 -2.314860   \n",
       "\n",
       "               7         8         9  ...        16        17        18  \\\n",
       "cluster                               ...                                 \n",
       "0        0.24438  0.248004  0.251948  ...  0.247737  0.251469  0.259140   \n",
       "1       -2.19942 -2.232040 -2.267535  ... -2.229637 -2.263223 -2.332263   \n",
       "\n",
       "               19        20        21        22        23        24      score  \n",
       "cluster                                                                         \n",
       "0        0.249625  0.235669  0.244511  0.237602  0.246901  0.249373   2.713394  \n",
       "1       -2.246622 -2.121021 -2.200595 -2.138417 -2.222110 -2.244355  13.503675  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = X_test_scaled.copy()\n",
    "df_test['score'] = y_test_scores\n",
    "df_test['cluster'] = np.where(df_test['score']<4, 0, 1)\n",
    "df_test['cluster'].value_counts()\n",
    "\n",
    "df_test.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 15)                390       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 25)                400       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 25)                650       \n",
      "=================================================================\n",
      "Total params: 3,767\n",
      "Trainable params: 3,767\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 2s 25ms/step - loss: 4.0388 - val_loss: 2.8462\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.1013 - val_loss: 2.4863\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.6017 - val_loss: 2.2868\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.5929 - val_loss: 2.1532\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 2.0227 - val_loss: 2.0259\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.9239 - val_loss: 1.9145\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.0788 - val_loss: 1.8109\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.6313 - val_loss: 1.7250\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.6779 - val_loss: 1.6528\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.8649 - val_loss: 1.6014\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.6502 - val_loss: 1.5617\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.7269 - val_loss: 1.5245\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.5261 - val_loss: 1.4932\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.5200 - val_loss: 1.4658\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.5530 - val_loss: 1.4421\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1592 - val_loss: 1.4204\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.2309 - val_loss: 1.3984\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.2728 - val_loss: 1.3766\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.3335 - val_loss: 1.3603\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.3582 - val_loss: 1.3431\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.4222 - val_loss: 1.3261\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.1220 - val_loss: 1.3109\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.3180 - val_loss: 1.2964\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.3921 - val_loss: 1.2835\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.6606 - val_loss: 1.2716\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.2620 - val_loss: 1.2602\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2871 - val_loss: 1.2512\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1420 - val_loss: 1.2419\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.3032 - val_loss: 1.2337\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2103 - val_loss: 1.2258\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1405 - val_loss: 1.2186\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.2819 - val_loss: 1.2111\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 1.1565 - val_loss: 1.2045\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.2648 - val_loss: 1.1986\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1509 - val_loss: 1.1927\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1925 - val_loss: 1.1875\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9874 - val_loss: 1.1823\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0961 - val_loss: 1.1773\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.2309 - val_loss: 1.1723\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2108 - val_loss: 1.1679\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.3567 - val_loss: 1.1637\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1259 - val_loss: 1.1598\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.5232 - val_loss: 1.1563\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.1000 - val_loss: 1.1529\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.1551 - val_loss: 1.1492\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.0634 - val_loss: 1.1459\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.1673 - val_loss: 1.1425\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.1675 - val_loss: 1.1395\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.3652 - val_loss: 1.1366\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.1506 - val_loss: 1.1343\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9934 - val_loss: 1.1318\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.2026 - val_loss: 1.1292\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0049 - val_loss: 1.1266\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.2801 - val_loss: 1.1230\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.0814 - val_loss: 1.1206\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.9181 - val_loss: 1.1181\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0155 - val_loss: 1.1163\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.1771 - val_loss: 1.1146\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0824 - val_loss: 1.1125\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.3728 - val_loss: 1.1111\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9617 - val_loss: 1.1092\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1933 - val_loss: 1.1074\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.9702 - val_loss: 1.1058\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0392 - val_loss: 1.1042\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.1098 - val_loss: 1.1025\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.2030 - val_loss: 1.1008\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1657 - val_loss: 1.0992\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.8832 - val_loss: 1.0968\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.2149 - val_loss: 1.0954\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0548 - val_loss: 1.0941\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0334 - val_loss: 1.0930\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0075 - val_loss: 1.0919\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0181 - val_loss: 1.0910\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0752 - val_loss: 1.0899\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1281 - val_loss: 1.0890\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1067 - val_loss: 1.0878\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0344 - val_loss: 1.0865\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9584 - val_loss: 1.0854\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0798 - val_loss: 1.0844\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.1933 - val_loss: 1.0833\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.9592 - val_loss: 1.0823\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.9809 - val_loss: 1.0812\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0997 - val_loss: 1.0803\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0376 - val_loss: 1.0792\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.2315 - val_loss: 1.0783\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0692 - val_loss: 1.0774\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0963 - val_loss: 1.0765\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1931 - val_loss: 1.0757\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3589 - val_loss: 1.0749\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 1.1534 - val_loss: 1.0741\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0863 - val_loss: 1.0734\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9548 - val_loss: 1.0726\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1450 - val_loss: 1.0718\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1078 - val_loss: 1.0713\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.8691 - val_loss: 1.0703\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0541 - val_loss: 1.0695\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0859 - val_loss: 1.0688\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.0311 - val_loss: 1.0681\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9798 - val_loss: 1.0673\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.2627 - val_loss: 1.0666\n"
     ]
    }
   ],
   "source": [
    "clf3 = AutoEncoder(hidden_neurons =[25, 15, 10, 2, 10,15, 25])\n",
    "clf3.fit(X_train_scaled)\n",
    "\n",
    "# clf.decision_function: Predict raw anomaly score of X using the fitted detector.\n",
    "y_test_scores = clf3.decision_function(X_test_scaled)  # outlier scores\n",
    "y_test_scores = pd.Series(y_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ+0lEQVR4nO3de5SddX3v8ffHhMgtXGImIVzqFEtRpAVhiljUUgOUmyTtKi5yjjDUQKQWlRZPHS/Hg6unFc5Rl9ZjbSNQBkXkJiQFbElTgUUL6EDDNdBwDyQkwyUkQJUC3/PH7zfysLP37J257D2/zOe11qz9XH7Pfr77t5/9mWf/9rNnFBGYmVl53tLpAszMbGQc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAt0jSfZIO73QdE4Gkz0s6f5j1p0q6pZ011amhW1JImtpC21HVK+lGSadV5v+3pGckPT3S+5zoJB0u6clO1zHZOcABSY9JOqJm2Zte1BHx7oi4scn9tBwaJYuIv4qI02BsHnPu/1ckzaxZviLfd/coSx4VSdMknSNplaSXcr0X1qtL0l7A2cB+EbGbpJmS/lXSs5I2SLpV0mEt7POc/NgPGYeH1FGS3i/p3yS9IOm53D+/1em6SuQAL8hW/ovhUWDB0Iyk3wC261w5b3IlcALw34CdgQOAO4C5ddq+HXg2Itbn+ReBjwFdwK7AecA/DPdcShJwMvAc0DtGj2FCkLQTcC3wLWAGsAfwZeAXY7yfKWN5fxOVA7xF1bN0SYdIGpC0UdI6SV/PzW7OtxskvSjpfZLeIumLkh6XtF7SxZJ2rtzvKXnds5L+Z81+zpF0paTvS9oInJr3fWs+m1sr6f9Jmla5v5D0iXy2uEnSX0h6R95mo6TLq+1rHuPjkg7O0x/N97Vfnj9N0jWVur7f6DFX7u+rkp6X9KikY5p08feAUyrzvcDFNfXtnPtvMNf6RUlvyeum5P09I+kR4Lg6216Q++ypPMzR9EWen4sjgXkR8bOIeDUiXoiIb0fEBXXaLgN2z31xUUT8PCIejIjXAQGvkYJ8xjC7/QCwO/Bp4KSa5/dUSbc06ltJu0tams9sH5J0emXdOZKuyMfTJkn3SPp1SZ/Lx+ZqSUdV2v+RpJW57SOSPt6gj/6HpKtqln1L0jfqNP91gIi4NCJei4j/jIgbIuLuyranV/Z7v6SD8vJ3KQ1XbVAa0jyhss1Fkr4j6XpJLwG/m/viqny8PCrpU5X2jV7DZYmISf8DPAYcUbPsVOCWem2AW4GT8/SOwKF5uhsIYGplu48BDwF757Y/Ar6X1+1HOkN7PzAN+CrwX5X9nJPn55N+2W4HHAwcCkzN+1sJnFXZXwBLgZ2Ad5PObJbn/e8M3A/0NuiHi4Gz8/Ri4GHgjyvr/rRS1/eHecyn5rpPB6YAfwysATRc/wMPAu/K26wmnc0G0F2pYQkwPe/3P4CFed0ZwAPAXqRw/Em1LuAa4O+AHYBZwE+Bj9d7rmtqOxe4qcnxcyNwWp4+HHiyTpu7gVdyTd9tcn8XAJcD2wDPAn/Qat8CNwF/A2wLHAgMAnMrz9vPgd/Lx8/FpHc+X8j7Oh14tLKv44B3kH7x/A7wMnBQ7eME5gAvAbvk+anAeuDgOo9tp/yY+oFjgF1r1p8IPAX8Vt7vr+XjYBvS6+jzpNfKh4BNwL55u4uAF4DDSK+V7Unvkr6U2+8NPAL83nCv4dJ+Ol7ARPghBciLwIbKz8s0DvCbSW/7ZtbcTzebh9ly4BOV+X3zC3BqPrgurazbnvQirwb4zU1qPwu4ujIfwGGV+TuAz1bmvwZ8o8F9LQSW5umVwGnAD/P845UX7zk0D/CHah5XALsN0/9HAF8EvgIcTTqTnZq36yaF1S9IY8tD230cuDFP/wtwRmXdUUN1AbPztttV1i8AflKpt1GAf3eoD4Z5Dm6kSYDnddvm/fYOc1/bAxuB+Xn+74AlrfQt6ZfXa8D0yvqvABdVnrdllXUfJh33U/L89HxfuzSo7Rrg0/UeJ/Bj4PQ8fTxw/zCP8V2kwH0SeJV0wjE7r/unoX3UbPMB4GngLZVllwLn5OmLgIsr694LPFFzH58D/n6413BpPx5CecP8iNhl6Af4xDBtF5LeCj4g6WeSjh+m7e6k8BvyOG+Eyu6kM00AIuJl0tlJ1erqTH7Le62kp/Owyl8BM2u2WVeZ/s868zs2qPUm4AOSdiMF5mXAYUof1u0MrGiwXT2/vAIjPy6G2e+Q75HGmU+lZviE9BinsXlf7pGn39SXNe2GzuDW5rffG0jBOKvZgyA9H3NaaNdUpOGUS4E+SQc0aPb7pFC7Ps9fAhwjqavSplHf7g48FxGbKm2rfQSbHwvPRMRrlfmh+0LSMZJuy8MxG4Bj2fxYG9IPfDRPf5T0XNYVESsj4tSI2BPYP9f9jbx6L9I7v1q7A6sjDUU1emzV5//tpKGsDZXn/POk1x1s2Wt4wnKAj0BErIqIBaQAOA+4UtIOpLOXWmtIB9OQXyG9QNcBa4E9h1ZI2g54W+3uaua/Qxoq2CcidiIdlBr5o6nsKOIh0juPT5HO/DeRwmIR6Qz19XqbjcW+8/4fJ72lP5Y01FT1DOmdS21fPpWn15Je/NV1Q1aTzsBnVn5J7xQR726hrH8GDpG0Z9OWrduG9Ja+nl5SgD6hdBniFbn9ggbtq9YAMyRNryyr9lHLJL0VuIo0rDc7n9RcT+Nj7RrgNyXtTzoDv6SV/UTEA6Sz5/3zotWkYZtaa4C9hj7zyGofW/VYXE0aDtql8jM9Io7N+230Gi6KA3wE8gd8XTnQNuTFr5HGG1/nzS/OS4E/lfSrknYknTFfFhGvkq5u+LCk384fVH2Z5mE8nfQW+0VJ7ySNgY6lm4Az8y2k4YHqfK16j3k0FgIfioiXqgvzWeLlwF9Kmi7p7cCfAUMfpl4OfErSnpJ2Bfoq264FbgC+JmknpQ+W3yHpd5oVExH/TBrOuVrSwZKm5v2fIeljzbaXdKjSZXPTJG0n6bOks8Db67Tdg3Rly/Gk8esDSVe8nEcLV6NExGrg34CvSNpW0m+S+rOlMK0xDXgr6fl9NX9QelSjxhHxc9Lx/APgpxHxRL12kt4p6eyhX4hKl10uAG7LTc4HPpP7WpJ+LT/Xt5PG2f9c0jZK38n4MPDDBiX9FNgo6bO536dI2l/5csVhXsNFcYCPzNHAfZJeBL4JnJTfHr8M/CXwr/lt26HAhaS3kzeTzi5/DnwSICLuy9M/JJ1BbiJ9+DPcJVWfIQ0zbCKNz142xo/tJtIviZsbzL9Jg8c8YhHxcEQMNFj9SdKL+BHgFlJYXJjXfZc0fnoXcCebn8GfQgql+4HnSWHT6tDIH5LOPi8jfVB2L9BDOjtv5q3At0lDMU+R3l0cFxFr6rQ9GVgR6aqMp4d+gL/mjbPbZhaQPjNYA1wN/K+IWNbCdm+S3319ivSL8XnSMbe0yWb9wG8wzPAJ6bh9L3B7vlrkNlJ/np33ewXpePpBbnsNMCMiXiFdynkM6d3Y3wCn5DP4evW/Rgr4A0mvu2dIvxx2zk3qvoabPL4JZ+iTa5sA8hn6BtLwyKMdLsdsi0j6FdLw3m4RsbHT9UwGPgPvMEkflrR9Hn/7KnAP6aoMs2Lksek/I12x4/Buk635m32lmEd6yylggPRWzm+LrBj55GMd6aqQoztczqTiIRQzs0J5CMXMrFBtHUKZOXNmdHd3t3OXZmbFu+OOO56JiK7a5W0N8O7ubgYGGl0hZmZm9Uh6vN5yD6GYmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRVqqw/w7r7rOl2Cmdm42OoD3Mxsa9U0wCXtK2lF5WejpLMkzZC0TNKqfLtrOwo2M7OkaYBHxIMRcWBEHAgcTPqv5VeT/mns8ojYB1hO5Z/ImpnZ+NvSIZS5wMMR8TjpP8n05+X9wPwxrMvMzJrY0gA/Cbg0T8+OiLUA+XZWvQ0kLZI0IGlgcHBw5JWamdmbtBzgkqYBJwBXbMkOImJxRPRERE9X12Z/j9zMzEZoS87AjwHujIh1eX6dpDkA+Xb9WBdnZmaNbUmAL+CN4ROApUBvnu4FloxVUWZm1lxLAS5pe+BI4EeVxecCR0paldedO/blmZlZIy39T8yIeBl4W82yZ0lXpZiZWQf4m5hmZoVygJuZFcoBbmZWqJbGwEvkv0JoZls7n4GbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRVqUgR4d991/uuEZrbVmRQBbma2NXKAm5kVqtX/Sr+LpCslPSBppaT3SZohaZmkVfl21/Eu1szM3tDqGfg3gX+MiHcCBwArgT5geUTsAyzP82Zm1iZNA1zSTsAHgQsAIuKViNgAzAP6c7N+YP74lGhmZvW0cga+NzAI/L2kf5d0vqQdgNkRsRYg386qt7GkRZIGJA0MDg6OWeFmZpNdKwE+FTgI+E5EvAd4iS0YLomIxRHRExE9XV1dIyzTzMxqtRLgTwJPRsTtef5KUqCvkzQHIN+uH58SzcysnqYBHhFPA6sl7ZsXzQXuB5YCvXlZL7BkXCo0M7O6prbY7pPAJZKmAY8Af0QK/8slLQSeAE4cnxLNzKyelgI8IlYAPXVWzR3TaszMrGX+JqaZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhZpUAe7/zGNmW5NJFeBmZlsTB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlaolv6psaTHgE3Aa8CrEdEjaQZwGdANPAZ8JCKeH58yzcys1pacgf9uRBwYEUP/nb4PWB4R+wDL87yZmbXJaIZQ5gH9ebofmD/qaszMrGWtBngAN0i6Q9KivGx2RKwFyLez6m0oaZGkAUkDg4ODo6/YzMyAFsfAgcMiYo2kWcAySQ+0uoOIWAwsBujp6YkR1GhmZnW0dAYeEWvy7XrgauAQYJ2kOQD5dv14FWlmZptrGuCSdpA0fWgaOAq4F1gK9OZmvcCS8SrSzMw218oQymzgaklD7X8QEf8o6WfA5ZIWAk8AJ45fmWZmVqtpgEfEI8ABdZY/C8wdj6LMzKw5fxPTzKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrVMsBLmmKpH+XdG2enyFpmaRV+XbX8SvTzMxqbckZ+KeBlZX5PmB5ROwDLM/zZmbWJi0FuKQ9geOA8yuL5wH9ebofmD+mlZmZ2bBaPQP/BvDnwOuVZbMjYi1Avp1Vb0NJiyQNSBoYHBwcTa1jprvvOrr7rut0GWZmo9I0wCUdD6yPiDtGsoOIWBwRPRHR09XVNZK7MDOzOqa20OYw4ARJxwLbAjtJ+j6wTtKciFgraQ6wfjwLNTOzN2t6Bh4Rn4uIPSOiGzgJ+JeI+CiwFOjNzXqBJeNW5Rbw8IiZTRajuQ78XOBISauAI/O8mZm1SStDKL8UETcCN+bpZ4G5Y1+SmZm1wt/ENDMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I1DXBJ20r6qaS7JN0n6ct5+QxJyyStyre7jn+5ZmY2pJUz8F8AH4qIA4ADgaMlHQr0AcsjYh9geZ43M7M2aRrgkbyYZ7fJPwHMA/rz8n5g/ngUaGZm9bU0Bi5piqQVwHpgWUTcDsyOiLUA+XbWuFVpZmabaSnAI+K1iDgQ2BM4RNL+re5A0iJJA5IGBgcHR1immZnV2qKrUCJiA3AjcDSwTtIcgHy7vsE2iyOiJyJ6urq6RletmZn9UitXoXRJ2iVPbwccATwALAV6c7NeYMk41WhmZnVMbaHNHKBf0hRS4F8eEddKuhW4XNJC4AngxHGs08zMajQN8Ii4G3hPneXPAnPHoygzM2vO38Q0MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFCTOsC7+66ju++6TpdhZjYikzrAzcxK5gA3MyuUA9zMrFAOcDOzQjnAzcwK1cpfIyyCryYxs8nGZ+BmZoVygJuZFcoBbmZWKAe4mVmhHOBmZoVygJuZFcoBbmZWqKbXgUvaC7gY2A14HVgcEd+UNAO4DOgGHgM+EhHPj1+p9fn6bzObrFo5A38VODsi3gUcCvyJpP2APmB5ROwDLM/zZmbWJk0DPCLWRsSdeXoTsBLYA5gH9Odm/cD8carRzMzq2KIxcEndwHuA24HZEbEWUsgDsxpss0jSgKSBwcHBUZZrZmZDWg5wSTsCVwFnRcTGVreLiMUR0RMRPV1dXSOp0czM6mgpwCVtQwrvSyLiR3nxOklz8vo5wPrxKdHMzOppGuCSBFwArIyIr1dWLQV683QvsGTsyzMzs0Za+XOyhwEnA/dIWpGXfR44F7hc0kLgCeDEcanQzMzqahrgEXELoAar545tOWZm1ip/E9PMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcNJ/9fF/9jGz0jjAzcwK5QA3MyuUA7zCQylmVhIHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRWqaYBLulDSekn3VpbNkLRM0qp8u+v4lmlmZrVaOQO/CDi6ZlkfsDwi9gGW53kzM2ujpgEeETcDz9Usngf05+l+YP7YlmVmZs2MdAx8dkSsBci3sxo1lLRI0oCkgcHBwRHuzszMao37h5gRsTgieiKip6ura7x3Z2Y2aYw0wNdJmgOQb9ePXUlmZtaKkQb4UqA3T/cCS8amHDMza1UrlxFeCtwK7CvpSUkLgXOBIyWtAo7M82Zm1kZTmzWIiAUNVs0d41rMzGwL+JuYZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRWq6WWEE1V333WdLsHMrKN8Bm5mVigHuJlZoRzgZmaFcoCbmRXKAW5mm+nuu84XChTAAW5mVigHuJlZoYq7Drwdb+uG9vHYuceN+77Mtnbj+Xqa7K9Vn4GbmRXKAW5mVqjihlDMbHSGG3YY6RBl7X3Wu59G+93S5fYGn4GbmRXKAW5mVqhRDaFIOhr4JjAFOD8ixu2/03fySwV+K2edMtzQRKvHYyvHb6PXV6Plje6rlddps301u+96fVF7n42GY1pZ32gYaKT9PZ75MeIzcElTgG8DxwD7AQsk7TdWhZmZ2fBGM4RyCPBQRDwSEa8APwTmjU1ZZmbWjCJiZBtKfwgcHRGn5fmTgfdGxJk17RYBi/LsvsCDIy93XM0Enul0EVvINbeHax5/pdUL7a357RHRVbtwNGPgqrNss98GEbEYWDyK/bSFpIGI6Ol0HVvCNbeHax5/pdULE6Pm0QyhPAnsVZnfE1gzunLMzKxVownwnwH7SPpVSdOAk4ClY1OWmZk1M+IhlIh4VdKZwD+RLiO8MCLuG7PK2m/CD/PU4ZrbwzWPv9LqhQlQ84g/xDQzs87yNzHNzArlADczK9SkCnBJe0n6iaSVku6T9Ok6bQ6X9IKkFfnnS52otaamxyTdk+sZqLNekv5a0kOS7pZ0UCfqrNSzb6X/VkjaKOmsmjYd72dJF0paL+neyrIZkpZJWpVvd22w7dGSHsx93tfhmv+vpAfyc3+1pF0abDvscdTGes+R9FTluT+2wbYTqY8vq9T7mKQVDbZtbx9HxKT5AeYAB+Xp6cB/APvVtDkcuLbTtdbU9Bgwc5j1xwI/Jl2bfyhwe6drrtQ2BXia9EWECdXPwAeBg4B7K8v+D9CXp/uA8xo8poeBvYFpwF21x1Gbaz4KmJqnz6tXcyvHURvrPQf4TAvHzYTp45r1XwO+NBH6eFKdgUfE2oi4M09vAlYCe3S2qjExD7g4ktuAXSTN6XRR2Vzg4Yh4vNOF1IqIm4HnahbPA/rzdD8wv86mHfszEvVqjogbIuLVPHsb6TsZE0KDPm7FhOrjIZIEfAS4tB21NDOpArxKUjfwHuD2OqvfJ+kuST+W9O72VlZXADdIuiP/aYJaewCrK/NPMnF+MZ1E44N9ovUzwOyIWAvpFz4wq06bidzfHyO9G6un2XHUTmfmIZ8LGwxTTdQ+/gCwLiJWNVjf1j6elAEuaUfgKuCsiNhYs/pO0tv9A4BvAde0ubx6DouIg0h/+fFPJH2wZn1Lf9ag3fIXvE4ArqizeiL2c6sman9/AXgVuKRBk2bHUbt8B3gHcCCwljQkUWtC9jGwgOHPvtvax5MuwCVtQwrvSyLiR7XrI2JjRLyYp68HtpE0s81l1ta0Jt+uB64mvb2smqh/1uAY4M6IWFe7YiL2c7ZuaPgp366v02bC9bekXuB44L9HHoyt1cJx1BYRsS4iXouI14HvNqhjIvbxVOAPgMsatWl3H0+qAM/jVxcAKyPi6w3a7JbbIekQUh89274qN6tnB0nTh6ZJH1jdW9NsKXBKvhrlUOCFoWGADmt4tjLR+rliKdCbp3uBJXXaTKg/I6H0j1U+C5wQES83aNPKcdQWNZ/P/H6DOiZUH2dHAA9ExJP1Vnakj9v1aelE+AHeT3obdjewIv8cC5wBnJHbnAncR/rU+zbgtztc8965lrtyXV/Iy6s1i/TPNR4G7gF6JkBfb08K5J0ryyZUP5N+uawF/ot0xrcQeBuwHFiVb2fktrsD11e2PZZ0FdPDQ89JB2t+iDRePHRM/21tzY2Oow7V+718nN5NCuU5E72P8/KLho7fStuO9rG/Sm9mVqhJNYRiZrY1cYCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVqj/D1WwfvnNjItfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_test_scores, bins='auto')  \n",
    "plt.title(\"Histogram with Model Clf3 Anomaly Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.284756</td>\n",
       "      <td>0.233752</td>\n",
       "      <td>0.213252</td>\n",
       "      <td>0.282784</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>0.268499</td>\n",
       "      <td>0.256723</td>\n",
       "      <td>0.330233</td>\n",
       "      <td>0.307315</td>\n",
       "      <td>0.264452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274579</td>\n",
       "      <td>0.268014</td>\n",
       "      <td>0.261233</td>\n",
       "      <td>0.300980</td>\n",
       "      <td>0.257770</td>\n",
       "      <td>0.306561</td>\n",
       "      <td>0.246576</td>\n",
       "      <td>0.235519</td>\n",
       "      <td>0.266344</td>\n",
       "      <td>1.953432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.405669</td>\n",
       "      <td>-2.351177</td>\n",
       "      <td>-2.171415</td>\n",
       "      <td>-1.715717</td>\n",
       "      <td>-2.212427</td>\n",
       "      <td>-2.263555</td>\n",
       "      <td>-2.649875</td>\n",
       "      <td>-2.384148</td>\n",
       "      <td>-2.375294</td>\n",
       "      <td>-2.013565</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.580048</td>\n",
       "      <td>-2.536069</td>\n",
       "      <td>-2.122499</td>\n",
       "      <td>-2.475651</td>\n",
       "      <td>-2.708152</td>\n",
       "      <td>-3.006297</td>\n",
       "      <td>-2.566102</td>\n",
       "      <td>-2.784837</td>\n",
       "      <td>-2.326757</td>\n",
       "      <td>14.650185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "cluster                                                                         \n",
       "0        0.284756  0.233752  0.213252  0.282784  0.304749  0.268499  0.256723   \n",
       "1       -2.405669 -2.351177 -2.171415 -1.715717 -2.212427 -2.263555 -2.649875   \n",
       "\n",
       "                7         8         9  ...        16        17        18  \\\n",
       "cluster                                ...                                 \n",
       "0        0.330233  0.307315  0.264452  ...  0.274579  0.268014  0.261233   \n",
       "1       -2.384148 -2.375294 -2.013565  ... -2.580048 -2.536069 -2.122499   \n",
       "\n",
       "               19        20        21        22        23        24      score  \n",
       "cluster                                                                         \n",
       "0        0.300980  0.257770  0.306561  0.246576  0.235519  0.266344   1.953432  \n",
       "1       -2.475651 -2.708152 -3.006297 -2.566102 -2.784837 -2.326757  14.650185  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = X_test_scaled.copy()\n",
    "df_test['score'] = y_test_scores\n",
    "df_test['cluster'] = np.where(df_test['score']<4, 0, 1)\n",
    "df_test['cluster'].value_counts()\n",
    "\n",
    "df_test.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.248812</td>\n",
       "      <td>0.235591</td>\n",
       "      <td>0.254013</td>\n",
       "      <td>0.239429</td>\n",
       "      <td>0.239101</td>\n",
       "      <td>0.255499</td>\n",
       "      <td>0.257207</td>\n",
       "      <td>0.24438</td>\n",
       "      <td>0.248004</td>\n",
       "      <td>0.251948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247737</td>\n",
       "      <td>0.251469</td>\n",
       "      <td>0.259140</td>\n",
       "      <td>0.249625</td>\n",
       "      <td>0.235669</td>\n",
       "      <td>0.244511</td>\n",
       "      <td>0.237602</td>\n",
       "      <td>0.246901</td>\n",
       "      <td>0.249373</td>\n",
       "      <td>2.717365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.239305</td>\n",
       "      <td>-2.120321</td>\n",
       "      <td>-2.286113</td>\n",
       "      <td>-2.154863</td>\n",
       "      <td>-2.151912</td>\n",
       "      <td>-2.299489</td>\n",
       "      <td>-2.314860</td>\n",
       "      <td>-2.19942</td>\n",
       "      <td>-2.232040</td>\n",
       "      <td>-2.267535</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.229637</td>\n",
       "      <td>-2.263223</td>\n",
       "      <td>-2.332263</td>\n",
       "      <td>-2.246622</td>\n",
       "      <td>-2.121021</td>\n",
       "      <td>-2.200595</td>\n",
       "      <td>-2.138417</td>\n",
       "      <td>-2.222110</td>\n",
       "      <td>-2.244355</td>\n",
       "      <td>13.492314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "cluster                                                                         \n",
       "0        0.248812  0.235591  0.254013  0.239429  0.239101  0.255499  0.257207   \n",
       "1       -2.239305 -2.120321 -2.286113 -2.154863 -2.151912 -2.299489 -2.314860   \n",
       "\n",
       "               7         8         9  ...        16        17        18  \\\n",
       "cluster                               ...                                 \n",
       "0        0.24438  0.248004  0.251948  ...  0.247737  0.251469  0.259140   \n",
       "1       -2.19942 -2.232040 -2.267535  ... -2.229637 -2.263223 -2.332263   \n",
       "\n",
       "               19        20        21        22        23        24      score  \n",
       "cluster                                                                         \n",
       "0        0.249625  0.235669  0.244511  0.237602  0.246901  0.249373   2.717365  \n",
       "1       -2.246622 -2.121021 -2.200595 -2.138417 -2.222110 -2.244355  13.492314  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Achieve Model Stability by Aggregating Multiple Models\n",
    "* Unsupervised techniques can detect many outliers. But due to its unspervised nature it is not stable, meaning overfitting to a specific dataset.\n",
    "* The solution is to train multiple models then aggregate the scores. \n",
    "* There are four methods to aggregate the outcome:\n",
    "* (1) Average: average scores of all detectors.\n",
    "* (2) Maximum of Maximum (MOM)\n",
    "* (3) Average of Maximum (AOM)\n",
    "* (4) Maximum of Average (MOA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.combination import aom, moa, average, maximization\n",
    "\n",
    "# Put all the predictions in a data frame\n",
    "train_scores = pd.DataFrame({'clf1': clf1.decision_scores_,\n",
    "                             'clf2': clf2.decision_scores_,\n",
    "                             'clf3': clf3.decision_scores_\n",
    "                            })\n",
    "\n",
    "test_scores  = pd.DataFrame({'clf1': clf1.decision_function(X_test_scaled),\n",
    "                             'clf2': clf2.decision_function(X_test_scaled),\n",
    "                             'clf3': clf3.decision_function(X_test_scaled) \n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf1</th>\n",
       "      <th>clf2</th>\n",
       "      <th>clf3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.957072</td>\n",
       "      <td>1.982249</td>\n",
       "      <td>2.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.790600</td>\n",
       "      <td>1.808246</td>\n",
       "      <td>1.818738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.198084</td>\n",
       "      <td>2.227000</td>\n",
       "      <td>2.236369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.143363</td>\n",
       "      <td>2.176961</td>\n",
       "      <td>2.189760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.920019</td>\n",
       "      <td>1.932912</td>\n",
       "      <td>1.947401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       clf1      clf2      clf3\n",
       "0  1.957072  1.982249  2.000097\n",
       "1  1.790600  1.808246  1.818738\n",
       "2  2.198084  2.227000  2.236369\n",
       "3  2.143363  2.176961  2.189760\n",
       "4  1.920019  1.932912  1.947401"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf1</th>\n",
       "      <th>clf2</th>\n",
       "      <th>clf3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.586388</td>\n",
       "      <td>2.608600</td>\n",
       "      <td>2.621929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.181094</td>\n",
       "      <td>2.210545</td>\n",
       "      <td>2.213401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.175470</td>\n",
       "      <td>2.178704</td>\n",
       "      <td>2.201436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.155936</td>\n",
       "      <td>2.191460</td>\n",
       "      <td>2.212148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.028136</td>\n",
       "      <td>2.053246</td>\n",
       "      <td>2.065866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       clf1      clf2      clf3\n",
       "0  2.586388  2.608600  2.621929\n",
       "1  2.181094  2.210545  2.213401\n",
       "2  2.175470  2.178704  2.201436\n",
       "3  2.155936  2.191460  2.212148\n",
       "4  2.028136  2.053246  2.065866"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although we did standardization before, it was for the variables.\n",
    "# Now we do the standardization for the decision scores\n",
    "from pyod.utils.utility import standardizer\n",
    "train_scores_norm, test_scores_norm = standardizer(train_scores,test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average\n",
    "The \"average\" function in PyOD averages the outlier scores from multiple estimators.\n",
    "See [PyOD API Reference](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.knn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.28345056, -0.28780256, -0.28746368, -0.32380907, -0.32975648,\n",
       "       -0.32898645, -0.37262915, -0.25824893, -0.27185412])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination by average\n",
    "y_by_average = average(test_scores_norm)\n",
    "y_by_average[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combination by average\n",
    "y_by_average = average(test_scores_norm)\n",
    "             \n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_by_average, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Combination by average\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears we can identify those >=0.0 as the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    450\n",
       "1     50\n",
       "Name: y_by_average_cluster, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(X_test_scaled)\n",
    "df_test['y_by_average_score'] = y_by_average\n",
    "df_test['y_by_average_cluster'] = np.where(df_test['y_by_average_score']<0, 0, 1)\n",
    "df_test['y_by_average_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>y_by_average_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_by_average_cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.284756</td>\n",
       "      <td>0.233752</td>\n",
       "      <td>0.213252</td>\n",
       "      <td>0.282784</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>0.268499</td>\n",
       "      <td>0.256723</td>\n",
       "      <td>0.330233</td>\n",
       "      <td>0.307315</td>\n",
       "      <td>0.264452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274579</td>\n",
       "      <td>0.268014</td>\n",
       "      <td>0.261233</td>\n",
       "      <td>0.300980</td>\n",
       "      <td>0.257770</td>\n",
       "      <td>0.306561</td>\n",
       "      <td>0.246576</td>\n",
       "      <td>0.235519</td>\n",
       "      <td>0.266344</td>\n",
       "      <td>-0.339979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.405669</td>\n",
       "      <td>-2.351177</td>\n",
       "      <td>-2.171415</td>\n",
       "      <td>-1.715717</td>\n",
       "      <td>-2.212427</td>\n",
       "      <td>-2.263555</td>\n",
       "      <td>-2.649875</td>\n",
       "      <td>-2.384148</td>\n",
       "      <td>-2.375294</td>\n",
       "      <td>-2.013565</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.580048</td>\n",
       "      <td>-2.536069</td>\n",
       "      <td>-2.122499</td>\n",
       "      <td>-2.475651</td>\n",
       "      <td>-2.708152</td>\n",
       "      <td>-3.006297</td>\n",
       "      <td>-2.566102</td>\n",
       "      <td>-2.784837</td>\n",
       "      <td>-2.326757</td>\n",
       "      <td>3.014735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0         1         2         3         4  \\\n",
       "y_by_average_cluster                                                     \n",
       "0                     0.284756  0.233752  0.213252  0.282784  0.304749   \n",
       "1                    -2.405669 -2.351177 -2.171415 -1.715717 -2.212427   \n",
       "\n",
       "                             5         6         7         8         9  ...  \\\n",
       "y_by_average_cluster                                                    ...   \n",
       "0                     0.268499  0.256723  0.330233  0.307315  0.264452  ...   \n",
       "1                    -2.263555 -2.649875 -2.384148 -2.375294 -2.013565  ...   \n",
       "\n",
       "                            16        17        18        19        20  \\\n",
       "y_by_average_cluster                                                     \n",
       "0                     0.274579  0.268014  0.261233  0.300980  0.257770   \n",
       "1                    -2.580048 -2.536069 -2.122499 -2.475651 -2.708152   \n",
       "\n",
       "                            21        22        23        24  \\\n",
       "y_by_average_cluster                                           \n",
       "0                     0.306561  0.246576  0.235519  0.266344   \n",
       "1                    -3.006297 -2.566102 -2.784837 -2.326757   \n",
       "\n",
       "                      y_by_average_score  \n",
       "y_by_average_cluster                      \n",
       "0                              -0.339979  \n",
       "1                               3.014735  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby('y_by_average_cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum of maximum\n",
    "Merge the outlier scores from multiple estimators by taking the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combination by max\n",
    "y_by_maximization = maximization(test_scores_norm)\n",
    "             \n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_by_maximization, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Combination by max\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, it appears we can identify those >=0.0 as the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    450\n",
       "1     50\n",
       "Name: y_by_maximization_cluster, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = X_test_scaled.copy()\n",
    "df_test['y_by_maximization_score'] = y_by_maximization\n",
    "df_test['y_by_maximization_cluster'] = np.where(df_test['y_by_maximization_score']<0, 0, 1)\n",
    "df_test['y_by_maximization_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>y_by_average_score</th>\n",
       "      <th>y_by_average_cluster</th>\n",
       "      <th>y_by_maximization_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_by_maximization_cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.284756</td>\n",
       "      <td>0.233752</td>\n",
       "      <td>0.213252</td>\n",
       "      <td>0.282784</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>0.268499</td>\n",
       "      <td>0.256723</td>\n",
       "      <td>0.330233</td>\n",
       "      <td>0.307315</td>\n",
       "      <td>0.264452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261233</td>\n",
       "      <td>0.300980</td>\n",
       "      <td>0.257770</td>\n",
       "      <td>0.306561</td>\n",
       "      <td>0.246576</td>\n",
       "      <td>0.235519</td>\n",
       "      <td>0.266344</td>\n",
       "      <td>-0.339979</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.338286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.405669</td>\n",
       "      <td>-2.351177</td>\n",
       "      <td>-2.171415</td>\n",
       "      <td>-1.715717</td>\n",
       "      <td>-2.212427</td>\n",
       "      <td>-2.263555</td>\n",
       "      <td>-2.649875</td>\n",
       "      <td>-2.384148</td>\n",
       "      <td>-2.375294</td>\n",
       "      <td>-2.013565</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.122499</td>\n",
       "      <td>-2.475651</td>\n",
       "      <td>-2.708152</td>\n",
       "      <td>-3.006297</td>\n",
       "      <td>-2.566102</td>\n",
       "      <td>-2.784837</td>\n",
       "      <td>-2.326757</td>\n",
       "      <td>3.014735</td>\n",
       "      <td>1</td>\n",
       "      <td>3.027822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0         1         2         3         4  \\\n",
       "y_by_maximization_cluster                                                     \n",
       "0                          0.284756  0.233752  0.213252  0.282784  0.304749   \n",
       "1                         -2.405669 -2.351177 -2.171415 -1.715717 -2.212427   \n",
       "\n",
       "                                  5         6         7         8         9  \\\n",
       "y_by_maximization_cluster                                                     \n",
       "0                          0.268499  0.256723  0.330233  0.307315  0.264452   \n",
       "1                         -2.263555 -2.649875 -2.384148 -2.375294 -2.013565   \n",
       "\n",
       "                           ...        18        19        20        21  \\\n",
       "y_by_maximization_cluster  ...                                           \n",
       "0                          ...  0.261233  0.300980  0.257770  0.306561   \n",
       "1                          ... -2.122499 -2.475651 -2.708152 -3.006297   \n",
       "\n",
       "                                 22        23        24  y_by_average_score  \\\n",
       "y_by_maximization_cluster                                                     \n",
       "0                          0.246576  0.235519  0.266344           -0.339979   \n",
       "1                         -2.566102 -2.784837 -2.326757            3.014735   \n",
       "\n",
       "                           y_by_average_cluster  y_by_maximization_score  \n",
       "y_by_maximization_cluster                                                 \n",
       "0                                             0                -0.338286  \n",
       "1                                             1                 3.027822  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby('y_by_maximization_cluster').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
